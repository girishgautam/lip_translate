{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64fe9c97-e336-4e85-8577-82a0d6b33b28",
   "metadata": {},
   "source": [
    "# Download dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0edeb0c-73d0-47d4-a608-03f98815ac03",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                           Version\n",
      "--------------------------------- ------------\n",
      "absl-py                           1.3.0\n",
      "altair                            4.2.0\n",
      "anyio                             3.6.2\n",
      "argon2-cffi                       21.3.0\n",
      "argon2-cffi-bindings              21.2.0\n",
      "astroid                           2.11.7\n",
      "asttokens                         2.0.8\n",
      "astunparse                        1.6.3\n",
      "attrs                             22.1.0\n",
      "autopep8                          1.6.0\n",
      "Babel                             2.10.3\n",
      "backcall                          0.2.0\n",
      "beautifulsoup4                    4.11.1\n",
      "bleach                            5.0.1\n",
      "blinker                           1.5\n",
      "branca                            0.5.0\n",
      "cachetools                        5.2.0\n",
      "certifi                           2022.9.24\n",
      "cffi                              1.15.1\n",
      "charset-normalizer                2.1.1\n",
      "click                             8.1.3\n",
      "cloudpickle                       2.2.0\n",
      "colorama                          0.4.5\n",
      "commonmark                        0.9.1\n",
      "cycler                            0.11.0\n",
      "Cython                            0.29.32\n",
      "dask                              2022.7.1\n",
      "db-dtypes                         1.0.4\n",
      "deap                              1.3.3\n",
      "debugpy                           1.6.3\n",
      "decorator                         5.1.1\n",
      "defusedxml                        0.7.1\n",
      "dill                              0.3.6\n",
      "entrypoints                       0.4\n",
      "etils                             0.8.0\n",
      "executing                         1.1.1\n",
      "fastapi                           0.110.0\n",
      "fastjsonschema                    2.16.2\n",
      "filelock                          3.12.4\n",
      "flake8                            4.0.1\n",
      "flatbuffers                       22.9.24\n",
      "folium                            0.12.1.post1\n",
      "fonttools                         4.38.0\n",
      "fsspec                            2022.10.0\n",
      "gast                              0.4.0\n",
      "gensim                            4.2.0\n",
      "gitdb                             4.0.9\n",
      "GitPython                         3.1.29\n",
      "google-api-core                   2.10.2\n",
      "google-api-python-client          2.50.0\n",
      "google-auth                       2.13.0\n",
      "google-auth-httplib2              0.2.0\n",
      "google-auth-oauthlib              0.4.6\n",
      "google-cloud-bigquery             2.34.4\n",
      "google-cloud-bigquery-storage     2.16.2\n",
      "google-cloud-core                 2.3.2\n",
      "google-cloud-storage              2.4.0\n",
      "google-crc32c                     1.5.0\n",
      "google-pasta                      0.2.0\n",
      "google-resumable-media            2.4.0\n",
      "google-trans-new                  1.1.9\n",
      "googleapis-common-protos          1.56.4\n",
      "grpcio                            1.50.0\n",
      "grpcio-status                     1.48.2\n",
      "h11                               0.12.0\n",
      "h5py                              3.7.0\n",
      "hide-code                         0.7.0\n",
      "htmlmin                           0.1.12\n",
      "httpcore                          0.15.0\n",
      "httplib2                          0.22.0\n",
      "httpx                             0.23.0\n",
      "huggingface-hub                   0.16.4\n",
      "idna                              3.4\n",
      "ImageHash                         4.3.1\n",
      "imageio                           2.22.2\n",
      "imbalanced-learn                  0.9.1\n",
      "imblearn                          0.0\n",
      "importlib-metadata                5.0.0\n",
      "importlib-resources               5.10.0\n",
      "iniconfig                         1.1.1\n",
      "ipdb                              0.13.9\n",
      "ipykernel                         6.15.3\n",
      "ipympl                            0.9.2\n",
      "ipython                           8.5.0\n",
      "ipython-genutils                  0.2.0\n",
      "ipywidgets                        7.7.2\n",
      "isort                             5.10.1\n",
      "jedi                              0.18.1\n",
      "Jinja2                            3.1.2\n",
      "joblib                            1.3.2\n",
      "json5                             0.9.10\n",
      "jsonschema                        4.16.0\n",
      "jupyter                           1.0.0\n",
      "jupyter_client                    7.4.3\n",
      "jupyter-console                   6.6.3\n",
      "jupyter-contrib-core              0.4.0\n",
      "jupyter-contrib-nbextensions      0.5.1\n",
      "jupyter_core                      5.7.1\n",
      "jupyter-highlight-selected-word   0.2.0\n",
      "jupyter_latex_envs                1.4.6\n",
      "jupyter-nbextensions-configurator 0.5.0\n",
      "jupyter-resource-usage            0.6.3\n",
      "jupyter-server                    1.21.0\n",
      "jupyterlab                        3.4.8\n",
      "jupyterlab-pygments               0.2.2\n",
      "jupyterlab_server                 2.16.1\n",
      "jupyterlab-widgets                1.1.1\n",
      "kaggle                            1.5.12\n",
      "keras                             2.10.0\n",
      "Keras-Preprocessing               1.1.2\n",
      "kiwisolver                        1.4.4\n",
      "lazy-object-proxy                 1.7.1\n",
      "libclang                          14.0.6\n",
      "locket                            1.0.0\n",
      "lxml                              4.9.1\n",
      "Markdown                          3.4.1\n",
      "MarkupSafe                        2.1.1\n",
      "matplotlib                        3.5.3\n",
      "matplotlib-inline                 0.1.6\n",
      "mccabe                            0.6.1\n",
      "memoized-property                 1.0.3\n",
      "missingno                         0.5.1\n",
      "mistune                           0.8.4\n",
      "mpmath                            1.3.0\n",
      "multimethod                       1.8\n",
      "nbclassic                         0.4.7\n",
      "nbclient                          0.7.0\n",
      "nbconvert                         6.5.4\n",
      "nbformat                          5.7.0\n",
      "nbresult                          0.0.9\n",
      "nest-asyncio                      1.5.6\n",
      "networkx                          2.8.7\n",
      "nltk                              3.7\n",
      "notebook                          6.4.12\n",
      "notebook_shim                     0.2.0\n",
      "numpy                             1.23.4\n",
      "nvidia-cublas-cu12                12.1.3.1\n",
      "nvidia-cuda-cupti-cu12            12.1.105\n",
      "nvidia-cuda-nvrtc-cu12            12.1.105\n",
      "nvidia-cuda-runtime-cu12          12.1.105\n",
      "nvidia-cudnn-cu12                 8.9.2.26\n",
      "nvidia-cufft-cu12                 11.0.2.54\n",
      "nvidia-curand-cu12                10.3.2.106\n",
      "nvidia-cusolver-cu12              11.4.5.107\n",
      "nvidia-cusparse-cu12              12.1.0.106\n",
      "nvidia-nccl-cu12                  2.18.1\n",
      "nvidia-nvjitlink-cu12             12.2.140\n",
      "nvidia-nvtx-cu12                  12.1.105\n",
      "oauthlib                          3.2.2\n",
      "opt-einsum                        3.3.0\n",
      "packaging                         21.3\n",
      "pandas                            1.4.4\n",
      "pandas-gbq                        0.17.9\n",
      "pandas-profiling                  3.3.0\n",
      "pandocfilters                     1.5.0\n",
      "parso                             0.8.3\n",
      "partd                             1.3.0\n",
      "patsy                             0.5.3\n",
      "pdfkit                            1.0.0\n",
      "pexpect                           4.8.0\n",
      "phik                              0.12.2\n",
      "pickleshare                       0.7.5\n",
      "Pillow                            9.1.1\n",
      "pip                               24.0\n",
      "platformdirs                      2.5.2\n",
      "plotly                            5.9.0\n",
      "pluggy                            1.0.0\n",
      "pmdarima                          2.0.1\n",
      "prometheus-client                 0.15.0\n",
      "promise                           2.3\n",
      "prompt-toolkit                    3.0.31\n",
      "proto-plus                        1.22.1\n",
      "protobuf                          3.19.6\n",
      "psutil                            5.9.3\n",
      "psycopg2-binary                   2.9.4\n",
      "ptyprocess                        0.7.0\n",
      "pure-eval                         0.2.2\n",
      "py                                1.11.0\n",
      "pyarrow                           8.0.0\n",
      "pyasn1                            0.4.8\n",
      "pyasn1-modules                    0.2.8\n",
      "pycodestyle                       2.8.0\n",
      "pycparser                         2.21\n",
      "pydantic                          1.9.2\n",
      "pydata-google-auth                1.4.0\n",
      "pydeck                            0.8.0b4\n",
      "pyflakes                          2.4.0\n",
      "Pygments                          2.13.0\n",
      "pylint                            2.14.5\n",
      "Pympler                           1.0.1\n",
      "pyparsing                         3.0.9\n",
      "pyrsistent                        0.18.1\n",
      "pytesseract                       0.3.10\n",
      "pytest                            7.1.3\n",
      "pytest-asyncio                    0.19.0\n",
      "python-dateutil                   2.8.2\n",
      "python-dotenv                     0.20.0\n",
      "python-multipart                  0.0.9\n",
      "python-slugify                    6.1.2\n",
      "pytz                              2022.1\n",
      "pytz-deprecation-shim             0.1.0.post0\n",
      "PyWavelets                        1.4.1\n",
      "PyYAML                            6.0.1\n",
      "pyzmq                             24.0.1\n",
      "qtconsole                         5.5.1\n",
      "QtPy                              2.4.1\n",
      "regex                             2022.9.13\n",
      "requests                          2.28.1\n",
      "requests-oauthlib                 1.3.1\n",
      "rfc3986                           1.5.0\n",
      "rich                              12.6.0\n",
      "rsa                               4.9\n",
      "sacremoses                        0.0.53\n",
      "safetensors                       0.3.3\n",
      "scikit-image                      0.19.3\n",
      "scikit-learn                      1.4.0\n",
      "scipy                             1.8.1\n",
      "seaborn                           0.11.2\n",
      "semver                            2.13.0\n",
      "Send2Trash                        1.8.0\n",
      "sentencepiece                     0.1.99\n",
      "setuptools                        63.2.0\n",
      "setuptools-scm                    6.4.2\n",
      "six                               1.16.0\n",
      "smart-open                        6.2.0\n",
      "smmap                             5.0.0\n",
      "sniffio                           1.3.0\n",
      "soupsieve                         2.3.2.post1\n",
      "stack-data                        0.5.1\n",
      "starlette                         0.36.3\n",
      "statsmodels                       0.13.2\n",
      "stopit                            1.1.2\n",
      "streamlit                         1.11.1\n",
      "sympy                             1.12\n",
      "tangled-up-in-unicode             0.2.0\n",
      "tenacity                          8.1.0\n",
      "tensorboard                       2.10.1\n",
      "tensorboard-data-server           0.6.1\n",
      "tensorboard-plugin-wit            1.8.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow                        2.10.0\r\n",
      "tensorflow-datasets               4.6.0\r\n",
      "tensorflow-estimator              2.10.0\r\n",
      "tensorflow-io-gcs-filesystem      0.27.0\r\n",
      "tensorflow-metadata               1.10.0\r\n",
      "termcolor                         2.0.1\r\n",
      "terminado                         0.16.0\r\n",
      "text-unidecode                    1.3\r\n",
      "threadpoolctl                     3.1.0\r\n",
      "tifffile                          2022.10.10\r\n",
      "tinycss2                          1.2.1\r\n",
      "tokenizers                        0.14.0\r\n",
      "toml                              0.10.2\r\n",
      "tomli                             2.0.1\r\n",
      "tomlkit                           0.11.5\r\n",
      "toolz                             0.12.0\r\n",
      "torch                             2.1.0\r\n",
      "tornado                           6.2\r\n",
      "TPOT                              0.11.7\r\n",
      "tqdm                              4.64.1\r\n",
      "traitlets                         5.5.0\r\n",
      "transformers                      4.34.0\r\n",
      "triton                            2.1.0\r\n",
      "typeguard                         2.13.3\r\n",
      "typing_extensions                 4.10.0\r\n",
      "tzdata                            2022.5\r\n",
      "tzlocal                           4.2\r\n",
      "Unidecode                         1.3.8\r\n",
      "update-checker                    0.18.0\r\n",
      "uritemplate                       4.1.1\r\n",
      "urllib3                           1.26.12\r\n",
      "uvicorn                           0.27.1\r\n",
      "validators                        0.20.0\r\n",
      "visions                           0.7.5\r\n",
      "watchdog                          2.1.9\r\n",
      "wcwidth                           0.2.5\r\n",
      "webencodings                      0.5.1\r\n",
      "websocket-client                  1.4.1\r\n",
      "Werkzeug                          2.2.2\r\n",
      "wheel                             0.42.0\r\n",
      "widgetsnbextension                3.6.1\r\n",
      "wrapt                             1.14.1\r\n",
      "xgboost                           1.6.2\r\n",
      "XlsxWriter                        3.0.3\r\n",
      "yapf                              0.32.0\r\n",
      "ydata-profiling                   4.1.2\r\n",
      "zipp                              3.10.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1664451c-07f0-4aa0-addb-4d094aa9ef08",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: matplotlib in /home/girishj/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (3.5.3)\n",
      "Requirement already satisfied: imageio in /home/girishj/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (2.22.2)\n",
      "Collecting gdown\n",
      "  Downloading gdown-5.1.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: tensorflow in /home/girishj/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (2.10.0)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /home/girishj/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from opencv-python) (1.23.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/girishj/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/girishj/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from matplotlib) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/girishj/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/girishj/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/girishj/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from matplotlib) (9.1.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/girishj/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/girishj/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/girishj/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from gdown) (4.11.1)\n",
      "Requirement already satisfied: filelock in /home/girishj/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from gdown) (3.12.4)\n",
      "Requirement already satisfied: requests[socks] in /home/girishj/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from gdown) (2.28.1)\n",
      "Requirement already satisfied: tqdm in /home/girishj/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from gdown) (4.64.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/girishj/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow) (1.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/girishj/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /home/girishj/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow) (22.9.24)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/girishj/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/girishj/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/girishj/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow) (1.50.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/girishj/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in /home/girishj/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/girishj/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/girishj/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow) (14.0.6)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/girishj/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /home/girishj/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow) (3.19.6)\n",
      "Requirement already satisfied: setuptools in /home/girishj/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow) (63.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/girishj/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in /home/girishj/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow) (2.10.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/girishj/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow) (0.27.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in /home/girishj/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/girishj/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow) (2.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/girishj/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow) (4.10.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/girishj/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/girishj/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/girishj/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/girishj/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/girishj/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/girishj/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/girishj/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/girishj/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/girishj/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.3.2.post1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/girishj/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from requests[socks]->gdown) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/girishj/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from requests[socks]->gdown) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/girishj/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/girishj/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from requests[socks]->gdown) (2022.9.24)\n",
      "Collecting PySocks!=1.5.7,>=1.5.6 (from requests[socks]->gdown)\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/girishj/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/girishj/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/girishj/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/girishj/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (1.3.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/girishj/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/girishj/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/girishj/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (3.2.2)\n",
      "Downloading opencv_python-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (62.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.2/62.2 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading gdown-5.1.0-py3-none-any.whl (17 kB)\n",
      "Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: PySocks, opencv-python, gdown\n",
      "Successfully installed PySocks-1.7.1 gdown-5.1.0 opencv-python-4.9.0.80\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python matplotlib imageio gdown tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6366c143-34ef-4a9a-90a0-95f67382fe9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-11 11:44:15.051183: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-11 11:44:16.190150: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/girishj/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2024-03-11 11:44:16.190172: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-03-11 11:44:16.298880: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-11 11:44:18.677237: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/girishj/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2024-03-11 11:44:18.677426: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/girishj/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2024-03-11 11:44:18.677440: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from matplotlib import pyplot as plt\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b809068-42de-4354-8ae3-2877f0e21cc7",
   "metadata": {},
   "source": [
    "# 1. Build Data Loading Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8235cd4f-cc2a-4413-a5c2-d1bbef7c1a25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_video(path:str) -> List[float]:\n",
    "    '''\n",
    "    this function loads a video file, preprocesses its frames by converting them to grayscale,\n",
    "    cropping them, and then normalizes them by subtracting the mean and dividing by the standard deviation.\n",
    "    These normalized frames are then returned for further processing\n",
    "    '''\n",
    "\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames = []\n",
    "    for _ in range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))):\n",
    "        ret, frame = cap.read()\n",
    "        frame = tf.image.rgb_to_grayscale(frame)\n",
    "        frames.append(frame[190:236,80:220,:])\n",
    "    cap.release()\n",
    "\n",
    "    mean = tf.math.reduce_mean(frames)\n",
    "    std = tf.math.reduce_std(tf.cast(frames, tf.float32))\n",
    "    return tf.cast((frames - mean), tf.float32) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e6e2e1e-69ba-4c0d-ba64-9b0924f68d5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# - This line creates a list vocab containing all the characters that are allowed in the vocabulary.\n",
    "#It includes lowercase letters, some special characters (' ', '?', '!'), and digits.\n",
    "vocab = [x for x in \"abcdefghijklmnopqrstuvwxyz'?!123456789 \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e67015d-61ab-40e8-bf13-1d9019552eba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocabulary is: ['', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', \"'\", '?', '!', '1', '2', '3', '4', '5', '6', '7', '8', '9', ' '] (size =40)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-11 11:45:17.508573: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/girishj/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2024-03-11 11:45:17.509340: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-03-11 11:45:17.509385: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (DESKTOP-T6TOAJH): /proc/driver/nvidia/version does not exist\n",
      "2024-03-11 11:45:17.511080: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# this code sets up mappings between characters and numbers, and vice versa, using TensorFlow's Keras API.\n",
    "# It defines the vocabulary and creates layers for character-to-number and number-to-character mappings,\n",
    "# which are essential for processing text data in machine learning models, especially for tasks like natural language processing (NLP) and text generation.\n",
    "\n",
    "char_to_num = tf.keras.layers.StringLookup(vocabulary=vocab, oov_token=\"\")\n",
    "num_to_char = tf.keras.layers.StringLookup(\n",
    "    vocabulary=char_to_num.get_vocabulary(), oov_token=\"\", invert=True\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"The vocabulary is: {char_to_num.get_vocabulary()} \"\n",
    "    f\"(size ={char_to_num.vocabulary_size()})\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6235f8b6-7fa6-421b-b4da-1bca06b2e36a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# char_to_num.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3acb1e92-87d8-47f9-8e63-0b1032ce7dc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# char_to_num(['n','i','c','k'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf515d52-f529-4a5d-8cfb-eddca286d75b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# num_to_char([14,  9,  3, 11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab5c221b-37ef-4fa5-833f-15edcdabd145",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_alignments(path:str) -> List[str]:\n",
    "    '''\n",
    "     this function loads alignments from a file, filters out silence tokens,\n",
    "     converts alignment tokens to numbers using the char_to_num mapping,\n",
    "     and returns them as a list of strings.\n",
    "\n",
    "    '''\n",
    "    with open(path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    tokens = []\n",
    "    for line in lines:\n",
    "        line = line.split()\n",
    "        if line[2] != 'sil':\n",
    "            tokens = [*tokens,' ',line[2]]\n",
    "    return char_to_num(tf.reshape(tf.strings.unicode_split(tokens, input_encoding='UTF-8'), (-1)))[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb8040d6-7067-445c-8c82-2ea9af68c3c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data(path: str):\n",
    "    '''\n",
    "    this function takes a path as input, extracts the filename, constructs paths to the video and alignment files,\n",
    "    loads the video frames and alignments, and returns them.\n",
    "\n",
    "    '''\n",
    "    path = bytes.decode(path.numpy())\n",
    "    file_name = path.split('/')[-1].split('.')[0]\n",
    "    # File name splitting for windows\n",
    "    # file_name = path.split('\\\\')[-1].split('.')[0]\n",
    "    video_path = os.path.join('data','s1',f'{file_name}.mpg')\n",
    "    alignment_path = os.path.join('data','alignments','s1',f'{file_name}.align')\n",
    "    frames = load_video(video_path)\n",
    "    alignments = load_alignments(alignment_path)\n",
    "\n",
    "    return frames, alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2b4849ba-d2d0-428c-97c9-9b2685f03ed6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# type(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9267009c-7c7f-44fa-8553-c507cfc86016",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_path = '\\\\wsl.localhost\\Ubuntu\\home\\girishj\\code\\girishgautam\\yt_lipnet\\LipNet-main\\data\\videos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7a03b94d-2b03-4ef1-a789-25a8f1b85b43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_path_2 = './data/s1/bbal6n.mpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8c8d046b-228b-4525-8319-0dedb7243273",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tf.convert_to_tensor(test_path).numpy().decode('utf-8').split('\\\\')[-1].split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "55c6a0df-714e-45b9-ad61-cb76b9bcf5ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# frames, alignments = load_data(tf.convert_to_tensor(test_path_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6d2c8259-4a8e-40c6-84eb-8e20653d851a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plt.imshow(frames[40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "641d930a-bad6-47e9-b505-014fa63d9e67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# type(alignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "868335c5-77dc-4ce8-8a49-4de70219b41e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# type(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "522c8518-66a2-4195-a3f0-ff953e960d22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Overall, this line of code takes the numerical alignments, converts them into strings using the num_to_char mapping,\n",
    "#and then concatenates them into a single string representation.\n",
    "\n",
    "# tf.strings.reduce_join([bytes.decode(x) for x in num_to_char(alignments.numpy()).numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0cfe628f-8e84-4eb4-9e2f-1a496145f0c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mappable_function(path:str) ->List[str]:\n",
    "    '''\n",
    "     this function allows the load_data function to be used within TensorFlow's computational graph\n",
    "     by wrapping it with tf.py_function, enabling it to be executed in a TensorFlow environment.\n",
    "    '''\n",
    "    result = tf.py_function(load_data, [path], (tf.float32, tf.int64))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e27668d-32f8-4297-a925-65c7062e0b6c",
   "metadata": {},
   "source": [
    "# 2. Create Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4252d132-f179-446c-9730-57f54140f8e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "887710a2-eba8-4fea-b422-3606c27ebb8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this code sets up a TensorFlow data pipeline for loading and processing video data, batching it into padded batches,\n",
    "# shuffling it, and splitting it into training and testing sets.\n",
    "# It ensures efficient processing and utilization of available system resources.\n",
    "\n",
    "data = tf.data.Dataset.list_files('./data/s1/*.mpg')\n",
    "data = data.shuffle(500, reshuffle_each_iteration=False)\n",
    "data = data.map(mappable_function)\n",
    "data = data.padded_batch(2, padded_shapes=([75,None,None,None],[40]))\n",
    "data = data.prefetch(tf.data.AUTOTUNE)\n",
    "# Added for split\n",
    "train = data.take(450)\n",
    "test = data.skip(450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0e7fb39b-da2f-4c7c-b9e3-9a4b0bb39396",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "501"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2f06ea1e-5aa2-401a-acfe-2bd020f5f6c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#this line of code fetches the next batch of data from the TensorFlow dataset data and converts it into NumPy arrays for further processing or analysis in the notebook.\n",
    "\n",
    "# frames, alignments = data.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "75d4210d-5e78-450d-a39c-d0558c4f238d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sample = data.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7bf46a3d-1950-46f2-8a16-12ecc61717eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# len(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "98ff101f-e103-4142-a2cc-20c799e6b7b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# val = sample.next(); val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1b93b1fc-b7a9-4dcc-a2da-05c859dfd7f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(val[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "33897776-031c-48cc-8383-d1d6b3d5be02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this code snippet saves an animation as a GIF file by extracting the first frame of the animation, scaling its pixel values to the range [0, 255], and then saving it using imageio.mimsave()\n",
    "\n",
    "# imageio.mimsave('./animation.gif', np.squeeze(val[0][0])* 255, fps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "85abdba9-8317-4ac0-8c74-04088a8e1aa8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plt.imshow(val[0][0][74])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "406fcf6d-c14b-4890-a242-e05b48b77ea7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tf.strings.reduce_join([num_to_char(word) for word in val[1][1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fc8e9d-0fc0-45cb-a31d-1621eb02a5a4",
   "metadata": {},
   "source": [
    "# 3. Design the Deep Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "63ce97d1-7da4-4a64-9d21-8556f296565b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv3D, LSTM, Dense, Dropout, Bidirectional, MaxPool3D, Activation, Reshape, SpatialDropout3D, BatchNormalization, TimeDistributed, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ce069db3-ac8b-41ce-8cd3-0c4e4286fbf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#retrieves the shape of the first element of the first batch of data in the TensorFlow dataset data,\n",
    "\n",
    "# data.as_numpy_iterator().next()[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2d31bf31-4577-46bf-acd5-72825c809ea1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# creating a model architecture\n",
    "def initiate_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv3D(128, 3, input_shape=(75,46,140,1), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPool3D((1,2,2)))\n",
    "\n",
    "    model.add(Conv3D(256, 3, padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPool3D((1,2,2)))\n",
    "\n",
    "    model.add(Conv3D(75, 3, padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPool3D((1,2,2)))\n",
    "\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "    model.add(Bidirectional(LSTM(128, kernel_initializer='Orthogonal', return_sequences=True)))\n",
    "    model.add(Dropout(.5))\n",
    "\n",
    "    model.add(Bidirectional(LSTM(128, kernel_initializer='Orthogonal', return_sequences=True)))\n",
    "    model.add(Dropout(.5))\n",
    "\n",
    "    model.add(Dense(char_to_num.vocabulary_size()+1, kernel_initializer='he_normal', activation='softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ae3ca1f6-5b15-43a1-8405-2c8e10b0eb63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = initiate_model()\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "305d5003-4868-4e70-a678-d235e0cc6bbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# yhat = model.predict(val[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3f5bc361-4dcd-4500-82d8-2b363059fde8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tf.strings.reduce_join([num_to_char(x) for x in tf.argmax(yhat[0],axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f8869b96-3368-4b99-ad86-c90b1c3e450f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "441fb19a-5b68-40c6-b064-b03f7504cf73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.output_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4038bac0-f480-4c2a-88a6-74e5c78316bd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 4. Setup Training Options and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "21d5e171-6dc6-42e9-b033-ab2788cb1f4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    '''\n",
    "    this scheduler function maintains the learning rate constant for the first 30 epochs\n",
    "    and then exponentially decays it with each subsequent epoch.\n",
    "    '''\n",
    "    if epoch < 30:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "93b07c65-5455-4694-9c2d-a4df07d72c24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def CTCLoss(y_true, y_pred):\n",
    "    '''\n",
    "     this function calculates the CTC loss between the true labels and predicted labels,\n",
    "     taking into account the variable-length nature of sequences using the input and label lengths.\n",
    "     It's commonly used in sequence-to-sequence tasks, such as speech recognition or handwriting recognition.\n",
    "\n",
    "     '''\n",
    "\n",
    "    batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
    "    input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
    "    label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
    "\n",
    "    input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "    label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "\n",
    "    loss = tf.keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "33769630-b326-4baf-b137-23a96a36e2df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ProduceExample(tf.keras.callbacks.Callback):\n",
    "    '''\n",
    "    this callback class is designed to print examples of original and predicted sequences at the end of each epoch during training,\n",
    "    which can be useful for monitoring the model's progress and debugging.\n",
    "    '''\n",
    "    def __init__(self, dataset) -> None:\n",
    "        self.dataset = dataset.as_numpy_iterator()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None) -> None:\n",
    "        data = self.dataset.next()\n",
    "        yhat = self.model.predict(data[0])\n",
    "        decoded = tf.keras.backend.ctc_decode(yhat, [75,75], greedy=False)[0][0].numpy()\n",
    "        for x in range(len(yhat)):\n",
    "            print('Original:', tf.strings.reduce_join(num_to_char(data[1][x])).numpy().decode('utf-8'))\n",
    "            print('Prediction:', tf.strings.reduce_join(num_to_char(decoded[x])).numpy().decode('utf-8'))\n",
    "            print('~'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "714bbf84-3257-432c-a906-bcdb777ade0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Model compilation\n",
    "def compile_model(model):\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.0001), loss=CTCLoss)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ab91437c-6b3f-4cb5-b2d0-fc5390d181da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = compile_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5ef38c1d-bc59-4376-97d5-7a2cf4de8196",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this line of code creates a ModelCheckpoint callback that will save the model's weights to the specified file path whenever the training loss improves\n",
    "checkpoint_callback = ModelCheckpoint(os.path.join('models','checkpoint'), monitor='loss', save_freq=1, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6a8a1971-7d80-417d-a5c2-0335106780ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this line of code creates a LearningRateScheduler callback that will adjust the learning rate during training according to the specified scheduler function\n",
    "schedule_callback = LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "de0d417e-e4b1-4b92-96e7-33263c2fbc83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#This callback can be used during model training to produce examples or monitor the model's performance at the end of each epoch,\n",
    "# providing useful insights into the model's behavior.\n",
    "example_callback = ProduceExample(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac1cb98-19e1-4946-b99c-b2a1422e8f07",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "325/450 [====================>.........] - ETA: 6:46 - loss: 2.7366"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7f59b0036180] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7f59b0036180] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "374/450 [=======================>......] - ETA: 4:05 - loss: 2.7267"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7f59dc0662c0] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7f59dc0662c0] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/450 [==============================] - ETA: 0s - loss: 2.7302"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7f5a000186c0] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7f5a000186c0] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "Original: bin red by m six now\n",
      "Prediction: bin red by m six now\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: place red in v seven again\n",
      "Prediction: place red in v seven again\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 1696s 4s/step - loss: 2.7302 - val_loss: 1.0058 - lr: 3.0197e-06\n",
      "Epoch 7/100\n",
      "  8/450 [..............................] - ETA: 23:55 - loss: 2.7282"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7f59f4014ec0] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7f59f4014ec0] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/450 [==============================] - ETA: 0s - loss: 2.7503"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7f5a405bd940] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7f5a405bd940] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "Original: set blue by n six now\n",
      "Prediction: set blue by n six now\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: set blue by h two now\n",
      "Prediction: set blue by h two now\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 1695s 4s/step - loss: 2.7503 - val_loss: 1.2769 - lr: 3.0197e-06\n",
      "Epoch 8/100\n",
      "123/450 [=======>......................] - ETA: 17:36 - loss: 2.6024"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7f59e801e180] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7f59e801e180] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/450 [==============================] - ETA: 0s - loss: 2.7172"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7f598c11a1c0] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7f598c11a1c0] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "Original: lay white in e five soon\n",
      "Prediction: lay white in e five son\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: bin red in f six please\n",
      "Prediction: bin red in f six please\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 1696s 4s/step - loss: 2.7172 - val_loss: 1.1369 - lr: 3.0197e-06\n",
      "Epoch 9/100\n",
      "370/450 [=======================>......] - ETA: 4:17 - loss: 2.6426"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7f59b802dc80] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7f59b802dc80] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/450 [==============================] - ETA: 0s - loss: 2.6678"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7f59d0003200] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7f59d0003200] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "Original: lay white in r four please\n",
      "Prediction: lay white in r four please\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: bin green by u three soon\n",
      "Prediction: bin gren by u thre son\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 1693s 4s/step - loss: 2.6678 - val_loss: 1.0267 - lr: 3.0197e-06\n",
      "Epoch 10/100\n",
      "178/450 [==========>...................] - ETA: 14:45 - loss: 2.5845"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7f59f405d200] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7f59f405d200] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/450 [==============================] - ETA: 0s - loss: 2.4274"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7f5a1402ef00] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7f5a1402ef00] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "Original: bin green with b seven again\n",
      "Prediction: bin gren with b seven again\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: lay red in k two now\n",
      "Prediction: lay red in k two now\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 1703s 4s/step - loss: 2.4274 - val_loss: 0.8469 - lr: 2.2371e-06\n",
      "Epoch 34/100\n",
      "216/450 [=============>................] - ETA: 12:38 - loss: 2.4649"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7f59f8039a00] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7f59f8039a00] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/450 [==============================] - ETA: 0s - loss: 2.4158"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7f5a7c0d6040] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7f5a7c0d6040] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "Original: lay red in d eight now\n",
      "Prediction: lay red in d eight now\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: bin red at f eight now\n",
      "Prediction: bin red at f eight now\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 1701s 4s/step - loss: 2.4158 - val_loss: 0.9466 - lr: 2.0242e-06\n",
      "Epoch 35/100\n",
      "450/450 [==============================] - ETA: 0s - loss: 2.3292"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7f59a40b0540] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7f59a40b0540] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "Original: place red at p five soon\n",
      "Prediction: place red at p five son\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: set white by c one soon\n",
      "Prediction: set white by c one son\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 1701s 4s/step - loss: 2.3292 - val_loss: 0.8177 - lr: 1.8316e-06\n",
      "Epoch 36/100\n",
      " 32/450 [=>............................] - ETA: 22:33 - loss: 2.4567"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7f59d0078ac0] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7f59d0078ac0] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/450 [==============================] - ETA: 0s - loss: 2.3454"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7f59f4096a80] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7f59f4096a80] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "Original: place blue at c one soon\n",
      "Prediction: place blue at c one son\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: place red with q four please\n",
      "Prediction: place red with q four please\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 1698s 4s/step - loss: 2.3454 - val_loss: 1.0753 - lr: 1.6573e-06\n",
      "Epoch 37/100\n",
      "206/450 [============>.................] - ETA: 13:11 - loss: 2.3536"
     ]
    }
   ],
   "source": [
    "history = model.fit(train, validation_data=test, epochs=100, callbacks=[checkpoint_callback, schedule_callback, example_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9e8542-7ea8-4710-9b89-ec687c8174d5",
   "metadata": {},
   "source": [
    "# 5. Make a Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "8ab9887d-ef9b-44ae-827f-0566ace96c63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "6db6f902-9e65-432e-a3f3-037ce56a27aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1vWscXs4Vt0a_1IH1-ct2TCgXAZT-N3_Y\n",
      "From (redirected): https://drive.google.com/uc?id=1vWscXs4Vt0a_1IH1-ct2TCgXAZT-N3_Y&confirm=t&uuid=f12e3f1f-4d24-43da-94a1-4c3dce24a04e\n",
      "To: /home/jupyter/checkpoints.zip\n",
      "100%|██████████| 94.5M/94.5M [00:03<00:00, 24.9MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models/checkpoint.index',\n",
       " 'models/__MACOSX/._checkpoint.index',\n",
       " 'models/checkpoint.data-00000-of-00001',\n",
       " 'models/__MACOSX/._checkpoint.data-00000-of-00001',\n",
       " 'models/checkpoint',\n",
       " 'models/__MACOSX/._checkpoint']"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# url = 'https://drive.google.com/uc?id=1vWscXs4Vt0a_1IH1-ct2TCgXAZT-N3_Y'\n",
    "# output = 'checkpoints.zip'\n",
    "# gdown.download(url, output, quiet=False)\n",
    "# gdown.extractall('checkpoints.zip', 'models_yt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2d98d552-c65c-4606-b984-601de28d0010",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f199c443ee0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('models/checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "10369a5c-92af-40ed-9b9b-5bab4b515fe1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.data.ops.dataset_ops._NumpyIterator at 0x7f199c324040>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = test.as_numpy_iterator()\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d482cc73-dd01-4619-b6ad-617204e8dbbc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7f18f40b5ac0] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7f18f40b5ac0] Warning MVs not available\n"
     ]
    }
   ],
   "source": [
    "sample = test_data.next()\n",
    "# sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4e51d0d2-661d-4e01-9f72-5ea7785728db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0403d94b-c7cf-4dc2-9ca8-46d591d65457",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(sample[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "48b95926-fe87-4987-a409-f67f65f46b4f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ REAL TEXT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=string, numpy=b'place white at q three again'>,\n",
       " <tf.Tensor: shape=(), dtype=string, numpy=b'lay red in e one again'>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('~'*100, 'REAL TEXT')\n",
    "[tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in sample[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "10741aa8-e5f5-480c-bc38-585385eb3b3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "decoded = tf.keras.backend.ctc_decode(yhat, input_length=[75,75], greedy=True)[0][0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d1ce753d-9402-4f84-be08-0b96dad47a2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ PREDICTIONS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=string, numpy=b'place white at q three again'>,\n",
       " <tf.Tensor: shape=(), dtype=string, numpy=b'lay red in e one again'>]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('~'*100, 'PREDICTIONS')\n",
    "[tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in decoded]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538f4e67-9eb3-46af-89dc-2e5205f277c9",
   "metadata": {},
   "source": [
    "# Test on a Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81375a62-eefd-4588-a058-0cb1127be169",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8e1adc9e-33a6-4f5b-b065-1d096f04e163",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample = load_data(tf.convert_to_tensor('./data/s1/bbab8n.mpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e9b7abc9-faa9-4a35-8950-209519139163",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ REAL TEXT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=string, numpy=b'bin blue at b eight now'>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('~'*100, 'REAL TEXT')\n",
    "[tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in [sample[1]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5e77aa96-25df-4f4a-b598-e4c0ac4499ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(tf.expand_dims(sample[0], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f6566383-0ec8-495d-8578-f30b7f80a848",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "decoded = tf.keras.backend.ctc_decode(yhat, input_length=[75], greedy=True)[0][0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "81e26a0b-faaa-463b-8c05-2c7693a14a9a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ PREDICTIONS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=string, numpy=b'bin wree at o one soon'>]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('~'*100, 'PREDICTIONS')\n",
    "[tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in decoded]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c371da3c-bba1-47c5-9898-5bae1a421322",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m117",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m117"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

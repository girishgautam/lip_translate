{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64fe9c97-e336-4e85-8577-82a0d6b33b28",
   "metadata": {},
   "source": [
    "# Download dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0edeb0c-73d0-47d4-a608-03f98815ac03",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                                  Version\n",
      "---------------------------------------- ---------------\n",
      "absl-py                                  1.4.0\n",
      "aiofiles                                 22.1.0\n",
      "aiohttp                                  3.9.3\n",
      "aiohttp-cors                             0.7.0\n",
      "aiorwlock                                1.4.0\n",
      "aiosignal                                1.3.1\n",
      "aiosqlite                                0.19.0\n",
      "annotated-types                          0.6.0\n",
      "anyio                                    4.2.0\n",
      "apache-beam                              2.46.0\n",
      "archspec                                 0.2.2\n",
      "argon2-cffi                              23.1.0\n",
      "argon2-cffi-bindings                     21.2.0\n",
      "array-record                             0.5.0\n",
      "arrow                                    1.3.0\n",
      "asttokens                                2.4.1\n",
      "astunparse                               1.6.3\n",
      "async-timeout                            4.0.3\n",
      "attrs                                    23.2.0\n",
      "Babel                                    2.14.0\n",
      "backoff                                  2.2.1\n",
      "beatrix_jupyterlab                       2024.129.184238\n",
      "beautifulsoup4                           4.12.3\n",
      "bleach                                   6.1.0\n",
      "blessed                                  1.20.0\n",
      "boltons                                  23.1.1\n",
      "Brotli                                   1.1.0\n",
      "cached-property                          1.5.2\n",
      "cachetools                               4.2.4\n",
      "certifi                                  2024.2.2\n",
      "cffi                                     1.16.0\n",
      "charset-normalizer                       3.3.2\n",
      "click                                    8.1.7\n",
      "cloud-tpu-client                         0.10\n",
      "cloud-tpu-profiler                       2.4.0\n",
      "cloudpickle                              2.2.1\n",
      "colorama                                 0.4.6\n",
      "colorful                                 0.5.6\n",
      "comm                                     0.2.1\n",
      "conda                                    24.1.1\n",
      "conda-libmamba-solver                    24.1.0\n",
      "conda-package-handling                   2.2.0\n",
      "conda_package_streaming                  0.9.0\n",
      "contourpy                                1.2.0\n",
      "crcmod                                   1.7\n",
      "cryptography                             42.0.2\n",
      "cycler                                   0.12.1\n",
      "Cython                                   3.0.8\n",
      "dacite                                   1.8.1\n",
      "dataproc_jupyter_plugin                  0.1.70\n",
      "db-dtypes                                1.2.0\n",
      "debugpy                                  1.8.1\n",
      "decorator                                5.1.1\n",
      "defusedxml                               0.7.1\n",
      "Deprecated                               1.2.14\n",
      "dill                                     0.3.1.1\n",
      "distlib                                  0.3.8\n",
      "distro                                   1.9.0\n",
      "dm-tree                                  0.1.8\n",
      "docker                                   7.0.0\n",
      "docopt                                   0.6.2\n",
      "docstring-parser                         0.15\n",
      "entrypoints                              0.4\n",
      "etils                                    1.6.0\n",
      "exceptiongroup                           1.2.0\n",
      "executing                                2.0.1\n",
      "explainable-ai-sdk                       1.3.3\n",
      "Farama-Notifications                     0.0.4\n",
      "fastapi                                  0.108.0\n",
      "fastavro                                 1.9.4\n",
      "fasteners                                0.19\n",
      "fastjsonschema                           2.19.1\n",
      "filelock                                 3.13.1\n",
      "flatbuffers                              23.5.26\n",
      "fonttools                                4.48.1\n",
      "fqdn                                     1.5.1\n",
      "frozenlist                               1.4.1\n",
      "fsspec                                   2024.2.0\n",
      "gast                                     0.4.0\n",
      "gcsfs                                    2024.2.0\n",
      "gdown                                    5.1.0\n",
      "gitdb                                    4.0.11\n",
      "GitPython                                3.1.41\n",
      "google-api-core                          1.34.1\n",
      "google-api-python-client                 1.8.0\n",
      "google-apitools                          0.5.31\n",
      "google-auth                              2.27.0\n",
      "google-auth-httplib2                     0.1.1\n",
      "google-auth-oauthlib                     0.4.6\n",
      "google-cloud-aiplatform                  1.41.0\n",
      "google-cloud-artifact-registry           1.11.1\n",
      "google-cloud-bigquery                    3.17.2\n",
      "google-cloud-bigquery-storage            2.16.2\n",
      "google-cloud-bigtable                    1.7.3\n",
      "google-cloud-core                        2.4.1\n",
      "google-cloud-datastore                   1.15.5\n",
      "google-cloud-dlp                         3.15.1\n",
      "google-cloud-jupyter-config              0.0.5\n",
      "google-cloud-language                    1.3.2\n",
      "google-cloud-monitoring                  2.19.1\n",
      "google-cloud-pubsub                      2.19.4\n",
      "google-cloud-pubsublite                  1.9.0\n",
      "google-cloud-recommendations-ai          0.7.1\n",
      "google-cloud-resource-manager            1.12.1\n",
      "google-cloud-spanner                     3.42.0\n",
      "google-cloud-storage                     2.14.0\n",
      "google-cloud-videointelligence           1.16.3\n",
      "google-cloud-vision                      3.7.0\n",
      "google-crc32c                            1.5.0\n",
      "google-pasta                             0.2.0\n",
      "google-resumable-media                   2.7.0\n",
      "googleapis-common-protos                 1.62.0\n",
      "gpustat                                  1.0.0\n",
      "greenlet                                 3.0.3\n",
      "grpc-google-iam-v1                       0.12.7\n",
      "grpc-interceptor                         0.15.4\n",
      "grpcio                                   1.48.1\n",
      "grpcio-status                            1.48.1\n",
      "gviz-api                                 1.10.0\n",
      "gymnasium                                0.28.1\n",
      "h11                                      0.14.0\n",
      "h5py                                     3.10.0\n",
      "hdfs                                     2.7.3\n",
      "htmlmin                                  0.1.12\n",
      "httplib2                                 0.21.0\n",
      "httptools                                0.6.1\n",
      "idna                                     3.6\n",
      "ImageHash                                4.3.1\n",
      "imageio                                  2.34.0\n",
      "importlib-metadata                       6.11.0\n",
      "importlib-resources                      6.1.1\n",
      "ipykernel                                6.29.2\n",
      "ipython                                  8.21.0\n",
      "ipython-genutils                         0.2.0\n",
      "ipython-sql                              0.5.0\n",
      "ipywidgets                               8.1.2\n",
      "isoduration                              20.11.0\n",
      "jaraco.classes                           3.3.1\n",
      "jax-jumpy                                1.0.0\n",
      "jedi                                     0.19.1\n",
      "jeepney                                  0.8.0\n",
      "Jinja2                                   3.1.3\n",
      "joblib                                   1.3.2\n",
      "json5                                    0.9.14\n",
      "jsonpatch                                1.33\n",
      "jsonpointer                              2.4\n",
      "jsonschema                               4.21.1\n",
      "jsonschema-specifications                2023.12.1\n",
      "jupyter_client                           7.4.9\n",
      "jupyter_core                             5.7.1\n",
      "jupyter-events                           0.9.0\n",
      "jupyter-http-over-ws                     0.0.8\n",
      "jupyter_server                           2.12.5\n",
      "jupyter_server_fileid                    0.9.1\n",
      "jupyter-server-mathjax                   0.2.6\n",
      "jupyter_server_proxy                     4.1.0\n",
      "jupyter_server_terminals                 0.5.2\n",
      "jupyter_server_ydoc                      0.8.0\n",
      "jupyter-ydoc                             0.2.5\n",
      "jupyterlab                               3.6.6\n",
      "jupyterlab_git                           0.44.0\n",
      "jupyterlab_pygments                      0.3.0\n",
      "jupyterlab_server                        2.25.3\n",
      "jupyterlab_widgets                       3.0.10\n",
      "jupytext                                 1.16.1\n",
      "keras                                    2.11.0\n",
      "keras-tuner                              1.4.6\n",
      "kernels-mixer                            0.0.7\n",
      "keyring                                  24.3.0\n",
      "keyrings.google-artifactregistry-auth    1.1.2\n",
      "kfp                                      2.5.0\n",
      "kfp-pipeline-spec                        0.2.2\n",
      "kfp-server-api                           2.0.5\n",
      "kiwisolver                               1.4.5\n",
      "kt-legacy                                1.0.5\n",
      "kubernetes                               26.1.0\n",
      "lazy_loader                              0.3\n",
      "libclang                                 16.0.6\n",
      "libmambapy                               1.5.6\n",
      "llvmlite                                 0.41.1\n",
      "lz4                                      4.3.3\n",
      "Markdown                                 3.5.2\n",
      "markdown-it-py                           3.0.0\n",
      "MarkupSafe                               2.0.1\n",
      "matplotlib                               3.8.3\n",
      "matplotlib-inline                        0.1.6\n",
      "mdit-py-plugins                          0.4.0\n",
      "mdurl                                    0.1.2\n",
      "menuinst                                 2.0.2\n",
      "mistune                                  3.0.2\n",
      "more-itertools                           10.2.0\n",
      "msgpack                                  1.0.7\n",
      "multidict                                6.0.5\n",
      "multimethod                              1.11\n",
      "nb_conda                                 2.2.1\n",
      "nb-conda-kernels                         2.3.1\n",
      "nbclassic                                1.0.0\n",
      "nbclient                                 0.8.0\n",
      "nbconvert                                7.16.0\n",
      "nbdime                                   3.2.0\n",
      "nbformat                                 5.9.2\n",
      "nest-asyncio                             1.6.0\n",
      "networkx                                 3.2.1\n",
      "notebook                                 6.5.4\n",
      "notebook_executor                        0.2\n",
      "notebook_shim                            0.2.4\n",
      "numba                                    0.58.1\n",
      "numpy                                    1.24.4\n",
      "nvidia-ml-py                             11.495.46\n",
      "oauth2client                             4.1.3\n",
      "oauthlib                                 3.2.2\n",
      "objsize                                  0.6.1\n",
      "opencensus                               0.11.4\n",
      "opencensus-context                       0.1.3\n",
      "opencv-python                            4.9.0.80\n",
      "opentelemetry-api                        1.22.0\n",
      "opentelemetry-exporter-otlp              1.22.0\n",
      "opentelemetry-exporter-otlp-proto-common 1.22.0\n",
      "opentelemetry-exporter-otlp-proto-grpc   1.22.0\n",
      "opentelemetry-exporter-otlp-proto-http   1.22.0\n",
      "opentelemetry-proto                      1.22.0\n",
      "opentelemetry-sdk                        1.22.0\n",
      "opentelemetry-semantic-conventions       0.43b0\n",
      "opt-einsum                               3.3.0\n",
      "orjson                                   3.9.14\n",
      "overrides                                7.7.0\n",
      "packaging                                23.2\n",
      "pandas                                   2.2.0\n",
      "pandas-profiling                         3.6.6\n",
      "pandocfilters                            1.5.0\n",
      "papermill                                2.5.0\n",
      "parso                                    0.8.3\n",
      "patsy                                    0.5.6\n",
      "pexpect                                  4.9.0\n",
      "phik                                     0.12.4\n",
      "pickleshare                              0.7.5\n",
      "pillow                                   10.2.0\n",
      "pip                                      24.0\n",
      "pkgutil_resolve_name                     1.3.10\n",
      "platformdirs                             3.11.0\n",
      "plotly                                   5.18.0\n",
      "pluggy                                   1.4.0\n",
      "prettytable                              3.9.0\n",
      "prometheus_client                        0.20.0\n",
      "promise                                  2.3\n",
      "prompt-toolkit                           3.0.42\n",
      "proto-plus                               1.23.0\n",
      "protobuf                                 3.19.6\n",
      "psutil                                   5.9.3\n",
      "ptyprocess                               0.7.0\n",
      "pure-eval                                0.2.2\n",
      "py-spy                                   0.3.14\n",
      "pyarrow                                  9.0.0\n",
      "pyasn1                                   0.5.1\n",
      "pyasn1-modules                           0.3.0\n",
      "pycosat                                  0.6.6\n",
      "pycparser                                2.21\n",
      "pydantic                                 2.6.1\n",
      "pydantic_core                            2.16.2\n",
      "pydot                                    1.4.2\n",
      "Pygments                                 2.17.2\n",
      "PyJWT                                    2.8.0\n",
      "pymongo                                  3.13.0\n",
      "pyOpenSSL                                24.0.0\n",
      "pyparsing                                3.1.1\n",
      "PySocks                                  1.7.1\n",
      "python-dateutil                          2.8.2\n",
      "python-dotenv                            1.0.1\n",
      "python-json-logger                       2.0.7\n",
      "pytz                                     2024.1\n",
      "pyu2f                                    0.1.5\n",
      "PyWavelets                               1.5.0\n",
      "PyYAML                                   6.0.1\n",
      "pyzmq                                    24.0.1\n",
      "ray                                      2.9.2\n",
      "ray-cpp                                  2.9.2\n",
      "referencing                              0.33.0\n",
      "regex                                    2023.12.25\n",
      "requests                                 2.31.0\n",
      "requests-oauthlib                        1.3.1\n",
      "requests-toolbelt                        0.10.1\n",
      "retrying                                 1.3.3\n",
      "rfc3339-validator                        0.1.4\n",
      "rfc3986-validator                        0.1.1\n",
      "rich                                     13.7.0\n",
      "rpds-py                                  0.18.0\n",
      "rsa                                      4.9\n",
      "ruamel.yaml                              0.18.6\n",
      "ruamel.yaml.clib                         0.2.8\n",
      "scikit-image                             0.22.0\n",
      "scikit-learn                             1.4.0\n",
      "scipy                                    1.11.4\n",
      "seaborn                                  0.12.2\n",
      "SecretStorage                            3.3.3\n",
      "Send2Trash                               1.8.2\n",
      "setuptools                               69.0.3\n",
      "shapely                                  2.0.2\n",
      "simpervisor                              1.0.0\n",
      "six                                      1.16.0\n",
      "smart-open                               6.4.0\n",
      "smmap                                    5.0.1\n",
      "sniffio                                  1.3.0\n",
      "soupsieve                                2.5\n",
      "SQLAlchemy                               2.0.27\n",
      "sqlparse                                 0.4.4\n",
      "stack-data                               0.6.2\n",
      "starlette                                0.32.0.post1\n",
      "statsmodels                              0.14.1\n",
      "tabulate                                 0.9.0\n",
      "tangled-up-in-unicode                    0.2.0\n",
      "tenacity                                 8.2.3\n",
      "tensorboard                              2.11.2\n",
      "tensorboard-data-server                  0.6.1\n",
      "tensorboard_plugin_profile               2.15.1\n",
      "tensorboard-plugin-wit                   1.8.1\n",
      "tensorboardX                             2.6\n",
      "tensorflow                               2.11.0\n",
      "tensorflow-cloud                         0.1.16\n",
      "tensorflow-datasets                      4.9.0\n",
      "tensorflow-estimator                     2.11.0\n",
      "tensorflow-hub                           0.16.1\n",
      "tensorflow-io                            0.29.0\n",
      "tensorflow-io-gcs-filesystem             0.29.0\n",
      "tensorflow-metadata                      0.14.0\n",
      "tensorflow-probability                   0.23.0\n",
      "tensorflow-serving-api                   2.11.0\n",
      "tensorflow-transform                     0.14.0\n",
      "termcolor                                2.4.0\n",
      "terminado                                0.18.0\n",
      "tf-keras                                 2.15.0\n",
      "threadpoolctl                            3.3.0\n",
      "tifffile                                 2024.2.12\n",
      "tinycss2                                 1.2.1\n",
      "toml                                     0.10.2\n",
      "tomli                                    2.0.1\n",
      "tornado                                  6.3.3\n",
      "tqdm                                     4.66.2\n",
      "traitlets                                5.9.0\n",
      "truststore                               0.8.0\n",
      "typeguard                                4.1.5\n",
      "typer                                    0.9.0\n",
      "types-python-dateutil                    2.8.19.20240106\n",
      "typing_extensions                        4.9.0\n",
      "typing-utils                             0.1.0\n",
      "tzdata                                   2024.1\n",
      "uri-template                             1.3.0\n",
      "uritemplate                              3.0.1\n",
      "urllib3                                  1.26.18\n",
      "uvicorn                                  0.27.1\n",
      "uvloop                                   0.19.0\n",
      "virtualenv                               20.21.0\n",
      "visions                                  0.7.5\n",
      "watchfiles                               0.21.0\n",
      "wcwidth                                  0.2.13\n",
      "webcolors                                1.13\n",
      "webencodings                             0.5.1\n",
      "websocket-client                         1.7.0\n",
      "websockets                               12.0\n",
      "Werkzeug                                 2.1.2\n",
      "wheel                                    0.42.0\n",
      "widgetsnbextension                       4.0.10\n",
      "witwidget                                1.8.1\n",
      "wordcloud                                1.9.3\n",
      "wrapt                                    1.16.0\n",
      "y-py                                     0.6.2\n",
      "yarl                                     1.9.4\n",
      "ydata-profiling                          4.6.4\n",
      "ypy-websocket                            0.8.4\n",
      "zipp                                     3.17.0\n",
      "zstandard                                0.22.0\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1664451c-07f0-4aa0-addb-4d094aa9ef08",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.10/site-packages (4.9.0.80)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (3.8.3)\n",
      "Requirement already satisfied: imageio in /opt/conda/lib/python3.10/site-packages (2.34.0)\n",
      "Requirement already satisfied: gdown in /opt/conda/lib/python3.10/site-packages (5.1.0)\n",
      "Requirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.11.0)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /opt/conda/lib/python3.10/site-packages (from opencv-python) (1.24.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (4.48.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.12.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown) (3.13.1)\n",
      "Requirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown) (4.66.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.48.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (16.0.6)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.19.6)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (69.0.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.11.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.29.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.27.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (3.5.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.1.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2024.2.2)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python matplotlib imageio gdown tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6366c143-34ef-4a9a-90a0-95f67382fe9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-07 08:59:55.668614: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-07 08:59:56.482056: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-07 08:59:59.100570: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib/python3.10/site-packages/cv2/../../lib64:/usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2024-03-07 08:59:59.101497: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib/python3.10/site-packages/cv2/../../lib64:/usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2024-03-07 08:59:59.101507: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from matplotlib import pyplot as plt\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b809068-42de-4354-8ae3-2877f0e21cc7",
   "metadata": {},
   "source": [
    "# 1. Build Data Loading Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8235cd4f-cc2a-4413-a5c2-d1bbef7c1a25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_video(path:str) -> List[float]: \n",
    "    '''\n",
    "    this function loads a video file, preprocesses its frames by converting them to grayscale,\n",
    "    cropping them, and then normalizes them by subtracting the mean and dividing by the standard deviation.\n",
    "    These normalized frames are then returned for further processing\n",
    "    '''\n",
    "\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames = []\n",
    "    for _ in range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))): \n",
    "        ret, frame = cap.read()\n",
    "        frame = tf.image.rgb_to_grayscale(frame)\n",
    "        frames.append(frame[190:236,80:220,:])\n",
    "    cap.release()\n",
    "    \n",
    "    mean = tf.math.reduce_mean(frames)\n",
    "    std = tf.math.reduce_std(tf.cast(frames, tf.float32))\n",
    "    return tf.cast((frames - mean), tf.float32) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5e6e2e1e-69ba-4c0d-ba64-9b0924f68d5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# - This line creates a list vocab containing all the characters that are allowed in the vocabulary. \n",
    "#It includes lowercase letters, some special characters (' ', '?', '!'), and digits.\n",
    "vocab = [x for x in \"abcdefghijklmnopqrstuvwxyz'?!123456789 \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0e67015d-61ab-40e8-bf13-1d9019552eba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocabulary is: ['', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', \"'\", '?', '!', '1', '2', '3', '4', '5', '6', '7', '8', '9', ' '] (size =40)\n"
     ]
    }
   ],
   "source": [
    "# this code sets up mappings between characters and numbers, and vice versa, using TensorFlow's Keras API.\n",
    "# It defines the vocabulary and creates layers for character-to-number and number-to-character mappings,\n",
    "# which are essential for processing text data in machine learning models, especially for tasks like natural language processing (NLP) and text generation.\n",
    "\n",
    "char_to_num = tf.keras.layers.StringLookup(vocabulary=vocab, oov_token=\"\")\n",
    "num_to_char = tf.keras.layers.StringLookup(\n",
    "    vocabulary=char_to_num.get_vocabulary(), oov_token=\"\", invert=True\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"The vocabulary is: {char_to_num.get_vocabulary()} \"\n",
    "    f\"(size ={char_to_num.vocabulary_size()})\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6235f8b6-7fa6-421b-b4da-1bca06b2e36a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# char_to_num.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3acb1e92-87d8-47f9-8e63-0b1032ce7dc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# char_to_num(['n','i','c','k'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cf515d52-f529-4a5d-8cfb-eddca286d75b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# num_to_char([14,  9,  3, 11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ab5c221b-37ef-4fa5-833f-15edcdabd145",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_alignments(path:str) -> List[str]:\n",
    "    '''\n",
    "     this function loads alignments from a file, filters out silence tokens,\n",
    "     converts alignment tokens to numbers using the char_to_num mapping,\n",
    "     and returns them as a list of strings.\n",
    "\n",
    "    '''    \n",
    "    with open(path, 'r') as f: \n",
    "        lines = f.readlines() \n",
    "    tokens = []\n",
    "    for line in lines:\n",
    "        line = line.split()\n",
    "        if line[2] != 'sil': \n",
    "            tokens = [*tokens,' ',line[2]]\n",
    "    return char_to_num(tf.reshape(tf.strings.unicode_split(tokens, input_encoding='UTF-8'), (-1)))[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cb8040d6-7067-445c-8c82-2ea9af68c3c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data(path: str):\n",
    "    '''\n",
    "    this function takes a path as input, extracts the filename, constructs paths to the video and alignment files,\n",
    "    loads the video frames and alignments, and returns them.\n",
    "    \n",
    "    '''   \n",
    "    path = bytes.decode(path.numpy())\n",
    "    file_name = path.split('/')[-1].split('.')[0]\n",
    "    # File name splitting for windows\n",
    "    # file_name = path.split('\\\\')[-1].split('.')[0]\n",
    "    video_path = os.path.join('data','s1',f'{file_name}.mpg')\n",
    "    alignment_path = os.path.join('data','alignments','s1',f'{file_name}.align')\n",
    "    frames = load_video(video_path) \n",
    "    alignments = load_alignments(alignment_path)\n",
    "    \n",
    "    return frames, alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2b4849ba-d2d0-428c-97c9-9b2685f03ed6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# type(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9267009c-7c7f-44fa-8553-c507cfc86016",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_path = '.\\\\data\\\\s1\\\\bbal6n.mpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7a03b94d-2b03-4ef1-a789-25a8f1b85b43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_path_2 = './data/s1/bbal6n.mpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8c8d046b-228b-4525-8319-0dedb7243273",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tf.convert_to_tensor(test_path).numpy().decode('utf-8').split('\\\\')[-1].split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "55c6a0df-714e-45b9-ad61-cb76b9bcf5ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# frames, alignments = load_data(tf.convert_to_tensor(test_path_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6d2c8259-4a8e-40c6-84eb-8e20653d851a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plt.imshow(frames[40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "641d930a-bad6-47e9-b505-014fa63d9e67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# type(alignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "868335c5-77dc-4ce8-8a49-4de70219b41e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# type(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "522c8518-66a2-4195-a3f0-ff953e960d22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Overall, this line of code takes the numerical alignments, converts them into strings using the num_to_char mapping,\n",
    "#and then concatenates them into a single string representation.\n",
    "\n",
    "# tf.strings.reduce_join([bytes.decode(x) for x in num_to_char(alignments.numpy()).numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0cfe628f-8e84-4eb4-9e2f-1a496145f0c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mappable_function(path:str) ->List[str]:\n",
    "    '''\n",
    "     this function allows the load_data function to be used within TensorFlow's computational graph\n",
    "     by wrapping it with tf.py_function, enabling it to be executed in a TensorFlow environment.\n",
    "    '''\n",
    "    result = tf.py_function(load_data, [path], (tf.float32, tf.int64))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e27668d-32f8-4297-a925-65c7062e0b6c",
   "metadata": {},
   "source": [
    "# 2. Create Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4252d132-f179-446c-9730-57f54140f8e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "887710a2-eba8-4fea-b422-3606c27ebb8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this code sets up a TensorFlow data pipeline for loading and processing video data, batching it into padded batches,\n",
    "# shuffling it, and splitting it into training and testing sets.\n",
    "# It ensures efficient processing and utilization of available system resources.\n",
    "\n",
    "data = tf.data.Dataset.list_files('./data/s1/*.mpg')\n",
    "data = data.shuffle(500, reshuffle_each_iteration=False)\n",
    "data = data.map(mappable_function)\n",
    "data = data.padded_batch(2, padded_shapes=([75,None,None,None],[40]))\n",
    "data = data.prefetch(tf.data.AUTOTUNE)\n",
    "# Added for split \n",
    "train = data.take(450)\n",
    "test = data.skip(450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0e7fb39b-da2f-4c7c-b9e3-9a4b0bb39396",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "501"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2f06ea1e-5aa2-401a-acfe-2bd020f5f6c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#this line of code fetches the next batch of data from the TensorFlow dataset data and converts it into NumPy arrays for further processing or analysis in the notebook.\n",
    "\n",
    "# frames, alignments = data.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "75d4210d-5e78-450d-a39c-d0558c4f238d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sample = data.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7bf46a3d-1950-46f2-8a16-12ecc61717eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# len(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "98ff101f-e103-4142-a2cc-20c799e6b7b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# val = sample.next(); val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1b93b1fc-b7a9-4dcc-a2da-05c859dfd7f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(val[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "33897776-031c-48cc-8383-d1d6b3d5be02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this code snippet saves an animation as a GIF file by extracting the first frame of the animation, scaling its pixel values to the range [0, 255], and then saving it using imageio.mimsave()\n",
    "\n",
    "# imageio.mimsave('./animation.gif', np.squeeze(val[0][0])* 255, fps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "85abdba9-8317-4ac0-8c74-04088a8e1aa8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plt.imshow(val[0][0][74])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "406fcf6d-c14b-4890-a242-e05b48b77ea7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tf.strings.reduce_join([num_to_char(word) for word in val[1][1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fc8e9d-0fc0-45cb-a31d-1621eb02a5a4",
   "metadata": {},
   "source": [
    "# 3. Design the Deep Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "63ce97d1-7da4-4a64-9d21-8556f296565b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Conv3D, LSTM, Dense, Dropout, Bidirectional, MaxPool3D, Activation, Reshape, SpatialDropout3D, BatchNormalization, TimeDistributed, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ce069db3-ac8b-41ce-8cd3-0c4e4286fbf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#retrieves the shape of the first element of the first batch of data in the TensorFlow dataset data,\n",
    "\n",
    "# data.as_numpy_iterator().next()[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2d31bf31-4577-46bf-acd5-72825c809ea1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# creating a model architecture\n",
    "def initiate_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv3D(128, 3, input_shape=(75,46,140,1), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPool3D((1,2,2)))\n",
    "\n",
    "    model.add(Conv3D(256, 3, padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPool3D((1,2,2)))\n",
    "\n",
    "    model.add(Conv3D(75, 3, padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPool3D((1,2,2)))\n",
    "\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "    model.add(Bidirectional(LSTM(128, kernel_initializer='Orthogonal', return_sequences=True)))\n",
    "    model.add(Dropout(.5))\n",
    "\n",
    "    model.add(Bidirectional(LSTM(128, kernel_initializer='Orthogonal', return_sequences=True)))\n",
    "    model.add(Dropout(.5))\n",
    "\n",
    "    model.add(Dense(char_to_num.vocabulary_size()+1, kernel_initializer='he_normal', activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ae3ca1f6-5b15-43a1-8405-2c8e10b0eb63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = initiate_model()\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "305d5003-4868-4e70-a678-d235e0cc6bbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# yhat = model.predict(val[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3f5bc361-4dcd-4500-82d8-2b363059fde8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tf.strings.reduce_join([num_to_char(x) for x in tf.argmax(yhat[0],axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f8869b96-3368-4b99-ad86-c90b1c3e450f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "441fb19a-5b68-40c6-b064-b03f7504cf73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.output_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4038bac0-f480-4c2a-88a6-74e5c78316bd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 4. Setup Training Options and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "21d5e171-6dc6-42e9-b033-ab2788cb1f4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    '''\n",
    "    this scheduler function maintains the learning rate constant for the first 30 epochs\n",
    "    and then exponentially decays it with each subsequent epoch.\n",
    "    '''\n",
    "    if epoch < 30:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "93b07c65-5455-4694-9c2d-a4df07d72c24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def CTCLoss(y_true, y_pred):\n",
    "    '''\n",
    "     this function calculates the CTC loss between the true labels and predicted labels,\n",
    "     taking into account the variable-length nature of sequences using the input and label lengths.\n",
    "     It's commonly used in sequence-to-sequence tasks, such as speech recognition or handwriting recognition.\n",
    "     \n",
    "     '''\n",
    "    \n",
    "    batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
    "    input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
    "    label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
    "\n",
    "    input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "    label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "\n",
    "    loss = tf.keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "33769630-b326-4baf-b137-23a96a36e2df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ProduceExample(tf.keras.callbacks.Callback): \n",
    "    '''\n",
    "    this callback class is designed to print examples of original and predicted sequences at the end of each epoch during training,\n",
    "    which can be useful for monitoring the model's progress and debugging.\n",
    "    '''\n",
    "    def __init__(self, dataset) -> None: \n",
    "        self.dataset = dataset.as_numpy_iterator()\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None) -> None:\n",
    "        data = self.dataset.next()\n",
    "        yhat = self.model.predict(data[0])\n",
    "        decoded = tf.keras.backend.ctc_decode(yhat, [75,75], greedy=False)[0][0].numpy()\n",
    "        for x in range(len(yhat)):           \n",
    "            print('Original:', tf.strings.reduce_join(num_to_char(data[1][x])).numpy().decode('utf-8'))\n",
    "            print('Prediction:', tf.strings.reduce_join(num_to_char(decoded[x])).numpy().decode('utf-8'))\n",
    "            print('~'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "714bbf84-3257-432c-a906-bcdb777ade0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Model compilation\n",
    "def compile_model(model):\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.0001), loss=CTCLoss)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ab91437c-6b3f-4cb5-b2d0-fc5390d181da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = compile_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5ef38c1d-bc59-4376-97d5-7a2cf4de8196",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this line of code creates a ModelCheckpoint callback that will save the model's weights to the specified file path whenever the training loss improves\n",
    "checkpoint_callback = ModelCheckpoint(os.path.join('models','checkpoint'), monitor='loss', save_freq=1, save_weights_only=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6a8a1971-7d80-417d-a5c2-0335106780ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this line of code creates a LearningRateScheduler callback that will adjust the learning rate during training according to the specified scheduler function\n",
    "schedule_callback = LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "de0d417e-e4b1-4b92-96e7-33263c2fbc83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#This callback can be used during model training to produce examples or monitor the model's performance at the end of each epoch,\n",
    "# providing useful insights into the model's behavior.\n",
    "example_callback = ProduceExample(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac1cb98-19e1-4946-b99c-b2a1422e8f07",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "325/450 [====================>.........] - ETA: 6:46 - loss: 2.7366"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7f59b0036180] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7f59b0036180] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "374/450 [=======================>......] - ETA: 4:05 - loss: 2.7267"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7f59dc0662c0] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7f59dc0662c0] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/450 [==============================] - ETA: 0s - loss: 2.7302"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7f5a000186c0] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7f5a000186c0] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "Original: bin red by m six now\n",
      "Prediction: bin red by m six now\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: place red in v seven again\n",
      "Prediction: place red in v seven again\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 1696s 4s/step - loss: 2.7302 - val_loss: 1.0058 - lr: 3.0197e-06\n",
      "Epoch 7/100\n",
      "  8/450 [..............................] - ETA: 23:55 - loss: 2.7282"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7f59f4014ec0] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7f59f4014ec0] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/450 [==============================] - ETA: 0s - loss: 2.7503"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7f5a405bd940] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7f5a405bd940] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "Original: set blue by n six now\n",
      "Prediction: set blue by n six now\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: set blue by h two now\n",
      "Prediction: set blue by h two now\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 1695s 4s/step - loss: 2.7503 - val_loss: 1.2769 - lr: 3.0197e-06\n",
      "Epoch 8/100\n",
      "123/450 [=======>......................] - ETA: 17:36 - loss: 2.6024"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7f59e801e180] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7f59e801e180] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/450 [==============================] - ETA: 0s - loss: 2.7172"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7f598c11a1c0] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7f598c11a1c0] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "Original: lay white in e five soon\n",
      "Prediction: lay white in e five son\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: bin red in f six please\n",
      "Prediction: bin red in f six please\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 1696s 4s/step - loss: 2.7172 - val_loss: 1.1369 - lr: 3.0197e-06\n",
      "Epoch 9/100\n",
      "370/450 [=======================>......] - ETA: 4:17 - loss: 2.6426"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7f59b802dc80] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7f59b802dc80] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/450 [==============================] - ETA: 0s - loss: 2.6678"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7f59d0003200] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7f59d0003200] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "Original: lay white in r four please\n",
      "Prediction: lay white in r four please\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: bin green by u three soon\n",
      "Prediction: bin gren by u thre son\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 1693s 4s/step - loss: 2.6678 - val_loss: 1.0267 - lr: 3.0197e-06\n",
      "Epoch 10/100\n",
      "178/450 [==========>...................] - ETA: 14:45 - loss: 2.5845"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7f59f405d200] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7f59f405d200] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/450 [==============================] - ETA: 0s - loss: 2.4274"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7f5a1402ef00] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7f5a1402ef00] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "Original: bin green with b seven again\n",
      "Prediction: bin gren with b seven again\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: lay red in k two now\n",
      "Prediction: lay red in k two now\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 1703s 4s/step - loss: 2.4274 - val_loss: 0.8469 - lr: 2.2371e-06\n",
      "Epoch 34/100\n",
      "216/450 [=============>................] - ETA: 12:38 - loss: 2.4649"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7f59f8039a00] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7f59f8039a00] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/450 [==============================] - ETA: 0s - loss: 2.4158"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7f5a7c0d6040] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7f5a7c0d6040] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "Original: lay red in d eight now\n",
      "Prediction: lay red in d eight now\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: bin red at f eight now\n",
      "Prediction: bin red at f eight now\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 1701s 4s/step - loss: 2.4158 - val_loss: 0.9466 - lr: 2.0242e-06\n",
      "Epoch 35/100\n",
      "450/450 [==============================] - ETA: 0s - loss: 2.3292"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7f59a40b0540] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7f59a40b0540] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "Original: place red at p five soon\n",
      "Prediction: place red at p five son\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: set white by c one soon\n",
      "Prediction: set white by c one son\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 1701s 4s/step - loss: 2.3292 - val_loss: 0.8177 - lr: 1.8316e-06\n",
      "Epoch 36/100\n",
      " 32/450 [=>............................] - ETA: 22:33 - loss: 2.4567"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7f59d0078ac0] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7f59d0078ac0] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/450 [==============================] - ETA: 0s - loss: 2.3454"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7f59f4096a80] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7f59f4096a80] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "Original: place blue at c one soon\n",
      "Prediction: place blue at c one son\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: place red with q four please\n",
      "Prediction: place red with q four please\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "450/450 [==============================] - 1698s 4s/step - loss: 2.3454 - val_loss: 1.0753 - lr: 1.6573e-06\n",
      "Epoch 37/100\n",
      "206/450 [============>.................] - ETA: 13:11 - loss: 2.3536"
     ]
    }
   ],
   "source": [
    "history = model.fit(train, validation_data=test, epochs=100, callbacks=[checkpoint_callback, schedule_callback, example_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9e8542-7ea8-4710-9b89-ec687c8174d5",
   "metadata": {},
   "source": [
    "# 5. Make a Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "8ab9887d-ef9b-44ae-827f-0566ace96c63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "6db6f902-9e65-432e-a3f3-037ce56a27aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1vWscXs4Vt0a_1IH1-ct2TCgXAZT-N3_Y\n",
      "From (redirected): https://drive.google.com/uc?id=1vWscXs4Vt0a_1IH1-ct2TCgXAZT-N3_Y&confirm=t&uuid=f12e3f1f-4d24-43da-94a1-4c3dce24a04e\n",
      "To: /home/jupyter/checkpoints.zip\n",
      "100%|| 94.5M/94.5M [00:03<00:00, 24.9MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models/checkpoint.index',\n",
       " 'models/__MACOSX/._checkpoint.index',\n",
       " 'models/checkpoint.data-00000-of-00001',\n",
       " 'models/__MACOSX/._checkpoint.data-00000-of-00001',\n",
       " 'models/checkpoint',\n",
       " 'models/__MACOSX/._checkpoint']"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# url = 'https://drive.google.com/uc?id=1vWscXs4Vt0a_1IH1-ct2TCgXAZT-N3_Y'\n",
    "# output = 'checkpoints.zip'\n",
    "# gdown.download(url, output, quiet=False)\n",
    "# gdown.extractall('checkpoints.zip', 'models_yt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2d98d552-c65c-4606-b984-601de28d0010",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f199c443ee0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('models/checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "10369a5c-92af-40ed-9b9b-5bab4b515fe1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.data.ops.dataset_ops._NumpyIterator at 0x7f199c324040>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = test.as_numpy_iterator()\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d482cc73-dd01-4619-b6ad-617204e8dbbc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x7f18f40b5ac0] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x7f18f40b5ac0] Warning MVs not available\n"
     ]
    }
   ],
   "source": [
    "sample = test_data.next()\n",
    "# sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4e51d0d2-661d-4e01-9f72-5ea7785728db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0403d94b-c7cf-4dc2-9ca8-46d591d65457",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(sample[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "48b95926-fe87-4987-a409-f67f65f46b4f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ REAL TEXT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=string, numpy=b'place white at q three again'>,\n",
       " <tf.Tensor: shape=(), dtype=string, numpy=b'lay red in e one again'>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('~'*100, 'REAL TEXT')\n",
    "[tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in sample[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "10741aa8-e5f5-480c-bc38-585385eb3b3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "decoded = tf.keras.backend.ctc_decode(yhat, input_length=[75,75], greedy=True)[0][0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d1ce753d-9402-4f84-be08-0b96dad47a2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ PREDICTIONS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=string, numpy=b'place white at q three again'>,\n",
       " <tf.Tensor: shape=(), dtype=string, numpy=b'lay red in e one again'>]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('~'*100, 'PREDICTIONS')\n",
    "[tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in decoded]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538f4e67-9eb3-46af-89dc-2e5205f277c9",
   "metadata": {},
   "source": [
    "# Test on a Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81375a62-eefd-4588-a058-0cb1127be169",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8e1adc9e-33a6-4f5b-b065-1d096f04e163",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample = load_data(tf.convert_to_tensor('./data/s1/bbab8n.mpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e9b7abc9-faa9-4a35-8950-209519139163",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ REAL TEXT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=string, numpy=b'bin blue at b eight now'>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('~'*100, 'REAL TEXT')\n",
    "[tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in [sample[1]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5e77aa96-25df-4f4a-b598-e4c0ac4499ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(tf.expand_dims(sample[0], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f6566383-0ec8-495d-8578-f30b7f80a848",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "decoded = tf.keras.backend.ctc_decode(yhat, input_length=[75], greedy=True)[0][0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "81e26a0b-faaa-463b-8c05-2c7693a14a9a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ PREDICTIONS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=string, numpy=b'bin wree at o one soon'>]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('~'*100, 'PREDICTIONS')\n",
    "[tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in decoded]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c371da3c-bba1-47c5-9898-5bae1a421322",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m117",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m117"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

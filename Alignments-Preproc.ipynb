{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31bf71bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /home/mathildaweston/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (4.9.0.80)\n",
      "Requirement already satisfied: matplotlib in /home/mathildaweston/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (3.5.3)\n",
      "Requirement already satisfied: imageio in /home/mathildaweston/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (2.22.2)\n",
      "Requirement already satisfied: tensorflow in /home/mathildaweston/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (2.10.0)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /home/mathildaweston/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from opencv-python) (1.23.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/mathildaweston/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/mathildaweston/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from matplotlib) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/mathildaweston/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/mathildaweston/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/mathildaweston/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from matplotlib) (9.1.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/mathildaweston/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/mathildaweston/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/mathildaweston/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow) (1.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/mathildaweston/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /home/mathildaweston/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow) (22.9.24)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/mathildaweston/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/mathildaweston/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/mathildaweston/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow) (1.50.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/mathildaweston/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in /home/mathildaweston/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/mathildaweston/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/mathildaweston/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow) (14.0.6)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/mathildaweston/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /home/mathildaweston/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow) (3.19.6)\n",
      "Requirement already satisfied: setuptools in /home/mathildaweston/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow) (63.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/mathildaweston/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in /home/mathildaweston/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow) (2.10.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/mathildaweston/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow) (0.27.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in /home/mathildaweston/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/mathildaweston/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow) (2.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/mathildaweston/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow) (4.4.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/mathildaweston/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/mathildaweston/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/mathildaweston/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/mathildaweston/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/mathildaweston/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/mathildaweston/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/mathildaweston/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/mathildaweston/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/mathildaweston/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/mathildaweston/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/mathildaweston/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/mathildaweston/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/mathildaweston/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/mathildaweston/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/mathildaweston/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/mathildaweston/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/mathildaweston/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2022.9.24)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/mathildaweston/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/mathildaweston/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/mathildaweston/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python matplotlib imageio tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96bc5c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-11 13:01:15.631761: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-11 13:01:15.948829: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-11 13:01:16.023499: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/mathildaweston/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2024-03-11 13:01:16.023515: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-03-11 13:01:16.069607: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-11 13:01:17.078054: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/mathildaweston/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2024-03-11 13:01:17.078157: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/mathildaweston/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2024-03-11 13:01:17.078162: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from matplotlib import pyplot as plt\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c55b701",
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers = [f's{i}' for i in [i for i in range(1, 35) if i != 21]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a7ebb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# speakers = 's1'\n",
    "\n",
    "# path_to_clean = ['/'.join([os.getcwd(),'data/alignments', speaker])]\n",
    "# path_to_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3837017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_names = []\n",
    "# for folder_path in paths_to_clean:\n",
    "#     for root, dirs, files in os.walk(folder_path):\n",
    "#         for file in files:\n",
    "#             if file.endswith('.align'):\n",
    "#                 file_name = file.replace(\".align\", \"\")\n",
    "#                 file_names.append(file_name)\n",
    "# len(file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c7d724d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-11 13:01:24.644890: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/mathildaweston/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2024-03-11 13:01:24.645541: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-03-11 13:01:24.645565: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (DESKTOP-12451Q9): /proc/driver/nvidia/version does not exist\n",
      "2024-03-11 13:01:24.647089: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "vocab = [x for x in \"abcdefghijklmnopqrstuvwxyz'?!123456789 \"]\n",
    "\n",
    "char_to_num = tf.keras.layers.StringLookup(vocabulary=vocab, oov_token=\"\")\n",
    "num_to_char = tf.keras.layers.StringLookup(\n",
    "    vocabulary=char_to_num.get_vocabulary(), oov_token=\"\", invert=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8998096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_alignments(path:str) -> List[str]: \n",
    "#     with open(path, 'r') as f: \n",
    "#         lines = f.readlines() \n",
    "#     tokens = []\n",
    "#     for line in lines:\n",
    "#         line = line.split()\n",
    "#         if line[2] != 'sil': #Removing the silences\n",
    "#             tokens = [*tokens,' ',line[2]]\n",
    "#     return char_to_num(tf.reshape(tf.strings.unicode_split(tokens, input_encoding='UTF-8'), (-1)))[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "183b8695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_align_data(file_name: str): \n",
    "#     alignment_path = os.path.join(path_to_clean[0], f'{file_name}.align')\n",
    "#     alignments = load_alignments(alignment_path).numpy().tolist()\n",
    "\n",
    "#     return alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d00d9d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_dict(file_names):\n",
    "#     align_dict = dict(zip(file_names, [load_align_data(file_name) for file_name in file_names]))\n",
    "#     return align_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46b90ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc_align(speaker: str):\n",
    "    path_to_clean = ['/'.join([os.getcwd(),'raw_alignments', speaker, 'align'])]\n",
    "    file_names = []\n",
    "    for folder_path in path_to_clean:\n",
    "        for root, dirs, files in os.walk(folder_path):\n",
    "            for file in files:\n",
    "                if file.endswith('.align'):\n",
    "                    file_name = file.replace(\".align\", \"\")\n",
    "                    file_names.append(file_name)\n",
    "    def load_alignments(path:str) -> List[str]: \n",
    "        with open(path, 'r') as f: \n",
    "            lines = f.readlines() \n",
    "        tokens = []\n",
    "        for line in lines:\n",
    "            line = line.split()\n",
    "            if line[2] != 'sil': #Removing the silences\n",
    "                tokens = [*tokens,' ',line[2]]\n",
    "        return char_to_num(tf.reshape(tf.strings.unicode_split(tokens, input_encoding='UTF-8'), (-1)))[1:]\n",
    "\n",
    "    def load_align_data(file_name: str): \n",
    "        alignment_path = os.path.join(path_to_clean[0], f'{file_name}.align')\n",
    "        alignments = load_alignments(alignment_path).numpy().tolist()\n",
    "\n",
    "        return alignments\n",
    "\n",
    "    def make_dict(file_names):\n",
    "        align_dict = dict(zip(file_names, [load_align_data(file_name) for file_name in file_names]))\n",
    "        return align_dict\n",
    "    \n",
    "    return make_dict(file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06b959b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_dict = preproc_align(speakers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "50e26b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s2_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4bc1ba",
   "metadata": {},
   "source": [
    "### Saving to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e4afe83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def save_json(speaker: str):\n",
    "    with open('/'.join([os.getcwd(), 'data/processed_alignments', f'{speaker}_proc_align.json']), 'w') as fp:\n",
    "        json.dump(preproc_align(speaker), fp)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# with open('/'.join([os.getcwd(), 'data/processed_alignments', speaker, f'{speaker}_proc_align.json']), 'w') as fp:\n",
    "#     json.dump(s1_aligns, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7480fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = open('/'.join([os.getcwd(), 'data/processed_alignments', speaker, f'{speaker}_proc_align.json']))\n",
    "\n",
    "# test_align = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bce6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_align"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4916df9",
   "metadata": {},
   "source": [
    "### Run and save for all speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bb081526",
   "metadata": {},
   "outputs": [],
   "source": [
    "for speaker in speakers:\n",
    "    save_json(speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e0f0f844",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('/'.join([os.getcwd(), 'data/processed_alignments', f's1_proc_align.json']))\n",
    "\n",
    "test_align = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4de9c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_align.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aba6957",
   "metadata": {},
   "source": [
    "### Make dictionary of selected alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7b441e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_speakers = ['s1', 's13', 's25']\n",
    "selected_file_names = ['pwwezn', 'srba3s', 'pwio7a', 'lriu9a', 'sbiy2n', 'bbwq7a', 'lgbx9a', 'prwb2p', 'swamzn', 'pgaizp', 'lbau5s', 'lwwd4p', 'lrwv8n', 'lbih5a', 'lwiv5a', 'pritzn', 'pbbt3s', 'sgwn4n', 'sgba2n', 'sgat3a', 'sgwx5a', 'lwae8n', 'bginzn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "846e6c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers_aligns = {}\n",
    "for file_name in selected_file_names:\n",
    "    for speaker in selected_speakers:\n",
    "        f = open('/'.join([os.getcwd(), 'data/processed_alignments', f'{speaker}_proc_align.json']))\n",
    "        speaker_alignments = json.load(f)\n",
    "        if file_name in speaker_alignments:\n",
    "            speakers_aligns[file_name] = speaker_alignments[file_name]\n",
    "            break\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "053be1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# speakers_aligns.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a99c5b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(speakers_aligns.keys()) == len(selected_file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dddd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('/'.join([os.getcwd(), 'data/processed_alignments', 'final_proc_align.json']), 'w') as fp:\n",
    "#     json.dump(speakers_aligns, fp)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m118",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m118"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-07 16:57:32.703596: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from matplotlib import pyplot as plt\n",
    "#import imageio\n",
    "import dlib\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-03-07 16:57:37--  http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
      "Resolving dlib.net (dlib.net)... 107.180.26.78\n",
      "Connecting to dlib.net (dlib.net)|107.180.26.78|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 64040097 (61M)\n",
      "Saving to: ‘shape_predictor_68_face_landmarks.dat.bz2.1’\n",
      "\n",
      "shape_predictor_68_ 100%[===================>]  61.07M   271KB/s    in 56s     \n",
      "\n",
      "2024-03-07 16:58:33 (1.08 MB/s) - ‘shape_predictor_68_face_landmarks.dat.bz2.1’ saved [64040097/64040097]\n",
      "\n",
      "bunzip2: Output file shape_predictor_68_face_landmarks.dat already exists.\n"
     ]
    }
   ],
   "source": [
    "!wget   http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2 # DOWNLOAD LINK\n",
    "!bunzip2 shape_predictor_68_face_landmarks.dat.bz2\n",
    "datFile =  \"shape_predictor_68_face_landmarks.dat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIP_MARGIN = 0.4                # Marginal rate for lip-only image.\n",
    "RESIZE = (70,30)                # Final image size\n",
    "for i in range(33):\n",
    "    if i != 18:\n",
    "        VIDEO_PATH=f'/Users/alessiastroni/code/girishgautam/lip_translate/raw_data/s{i+2}/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_list = os.listdir(VIDEO_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape_to_list(shape):\n",
    "    coords = []\n",
    "    for i in range(0, 68):\n",
    "        coords.append((shape.part(i).x, shape.part(i).y))\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video: pgag9n.mpg\n",
      "------------ images cropped ----------\n",
      "VIDEO COMPLETED: pgag9n.mpg\n",
      "Processing video: brwj7n.mpg\n",
      "------------ images cropped ----------\n",
      "VIDEO COMPLETED: brwj7n.mpg\n",
      "Processing video: bbwdza.mpg\n",
      "------------ images cropped ----------\n",
      "VIDEO COMPLETED: bbwdza.mpg\n",
      "Processing video: lgbc7p.mpg\n",
      "------------ images cropped ----------\n",
      "VIDEO COMPLETED: lgbc7p.mpg\n",
      "Processing video: lbbu1p.mpg\n",
      "------------ images cropped ----------\n",
      "VIDEO COMPLETED: lbbu1p.mpg\n",
      "Processing video: bgiq1n.mpg\n",
      "------------ images cropped ----------\n",
      "VIDEO COMPLETED: bgiq1n.mpg\n",
      "Processing video: lbim9p.mpg\n",
      "------------ images cropped ----------\n",
      "VIDEO COMPLETED: lbim9p.mpg\n",
      "Processing video: pbaf2s.mpg\n",
      "------------ images cropped ----------\n",
      "VIDEO COMPLETED: pbaf2s.mpg\n",
      "Processing video: srieza.mpg\n",
      "------------ images cropped ----------\n",
      "VIDEO COMPLETED: srieza.mpg\n",
      "Processing video: bgix7p.mpg\n",
      "------------ images cropped ----------\n",
      "VIDEO COMPLETED: bgix7p.mpg\n",
      "Processing video: lrbiza.mpg\n",
      "------------ images cropped ----------\n",
      "VIDEO COMPLETED: lrbiza.mpg\n",
      "Processing video: sgwg1n.mpg\n",
      "------------ images cropped ----------\n",
      "VIDEO COMPLETED: sgwg1n.mpg\n",
      "Processing video: prwt4s.mpg\n",
      "------------ images cropped ----------\n",
      "VIDEO COMPLETED: prwt4s.mpg\n",
      "Processing video: srwz2s.mpg\n",
      "------------ images cropped ----------\n",
      "VIDEO COMPLETED: srwz2s.mpg\n",
      "Processing video: bwiv9n.mpg\n",
      "------------ images cropped ----------\n",
      "VIDEO COMPLETED: bwiv9n.mpg\n",
      "Processing video: swbr9n.mpg\n",
      "------------ images cropped ----------\n",
      "VIDEO COMPLETED: swbr9n.mpg\n",
      "Processing video: pwag4s.mpg\n",
      "------------ images cropped ----------\n",
      "VIDEO COMPLETED: pwag4s.mpg\n",
      "Processing video: pbas1p.mpg\n",
      "------------ images cropped ----------\n",
      "VIDEO COMPLETED: pbas1p.mpg\n",
      "Processing video: lgwx1n.mpg\n",
      "------------ images cropped ----------\n",
      "VIDEO COMPLETED: lgwx1n.mpg\n",
      "Processing video: bgbk7p.mpg\n",
      "------------ images cropped ----------\n",
      "VIDEO COMPLETED: bgbk7p.mpg\n",
      "Processing video: lrwb7n.mpg\n",
      "------------ images cropped ----------\n",
      "VIDEO COMPLETED: lrwb7n.mpg\n",
      "Processing video: swik7n.mpg\n",
      "------------ images cropped ----------\n",
      "VIDEO COMPLETED: swik7n.mpg\n",
      "Processing video: pgat9p.mpg\n",
      "------------ images cropped ----------\n",
      "VIDEO COMPLETED: pgat9p.mpg\n",
      "Processing video: bwaj7p.mpg\n",
      "------------ images cropped ----------\n",
      "VIDEO COMPLETED: bwaj7p.mpg\n",
      "Processing video: srwl6a.mpg\n",
      "------------ images cropped ----------\n",
      "VIDEO COMPLETED: srwl6a.mpg\n",
      "Processing video: lbahza.mpg\n",
      "------------ images cropped ----------\n",
      "VIDEO COMPLETED: lbahza.mpg\n",
      "Processing video: pwwt9n.mpg\n",
      "------------ images cropped ----------\n",
      "VIDEO COMPLETED: pwwt9n.mpg\n",
      "Processing video: sbby1n.mpg\n",
      "------------ images cropped ----------\n",
      "VIDEO COMPLETED: sbby1n.mpg\n",
      "Processing video: briv4s.mpg\n",
      "------------ images cropped ----------\n",
      "VIDEO COMPLETED: briv4s.mpg\n",
      "Processing video: sbwy7p.mpg\n",
      "------------ images cropped ----------\n",
      "VIDEO COMPLETED: sbwy7p.mpg\n",
      "Processing video: srbr4s.mpg\n",
      "------------ images cropped ----------\n",
      "VIDEO COMPLETED: srbr4s.mpg\n",
      "Processing video: prbg2s.mpg\n",
      "------------ images cropped ----------\n",
      "VIDEO COMPLETED: prbg2s.mpg\n",
      "Processing video: sgwt1p.mpg\n",
      "------------ images cropped ----------\n",
      "VIDEO COMPLETED: sgwt1p.mpg\n",
      "Processing video: Thumbs.db\n",
      "Processing video: lwab7p.mpg\n",
      "------------ images cropped ----------\n",
      "VIDEO COMPLETED: lwab7p.mpg\n",
      "Processing video: srae2s.mpg\n",
      "------------ images cropped ----------\n",
      "VIDEO COMPLETED: srae2s.mpg\n",
      "Processing video: pbifza.mpg\n",
      "------------ images cropped ----------\n",
      "VIDEO COMPLETED: pbifza.mpg\n",
      "Processing video: lwab5n.mpg\n",
      "------------ images cropped ----------\n",
      "VIDEO COMPLETED: lwab5n.mpg\n",
      "Processing video: sgbm4a.mpg\n",
      "------------ images cropped ----------\n",
      "VIDEO COMPLETED: sgbm4a.mpg\n",
      "Processing video: pwwa8s.mpg\n",
      "------------ images cropped ----------\n",
      "VIDEO COMPLETED: pwwa8s.mpg\n",
      "Processing video: pginzs.mpg\n",
      "------------ images cropped ----------\n",
      "VIDEO COMPLETED: pginzs.mpg\n",
      "Processing video: pwig2a.mpg\n",
      "------------ images cropped ----------\n",
      "VIDEO COMPLETED: pwig2a.mpg\n",
      "Processing video: prwg6s.mpg\n",
      "------------ images cropped ----------\n",
      "VIDEO COMPLETED: prwg6s.mpg\n",
      "Processing video: lwau8s.mpg\n",
      "------------ images cropped ----------\n",
      "VIDEO COMPLETED: lwau8s.mpg\n",
      "Processing video: sbwy5n.mpg\n",
      "------------ images cropped ----------\n",
      "VIDEO COMPLETED: sbwy5n.mpg\n",
      "Processing video: sbby3p.mpg\n",
      "------------ images cropped ----------\n",
      "VIDEO COMPLETED: sbby3p.mpg\n",
      "Processing video: swir4a.mpg\n",
      "------------ images cropped ----------\n",
      "VIDEO COMPLETED: swir4a.mpg\n",
      "Processing video: sbbezs.mpg\n",
      "------------ images cropped ----------\n",
      "VIDEO COMPLETED: sbbezs.mpg\n",
      "Processing video: sray5p.mpg\n",
      "------------ images cropped ----------\n",
      "VIDEO COMPLETED: sray5p.mpg\n",
      "Processing video: srbl2a.mpg\n",
      "------------ images cropped ----------\n",
      "VIDEO COMPLETED: srbl2a.mpg\n"
     ]
    }
   ],
   "source": [
    "cropped_img_list=[]\n",
    "\n",
    "for vid_name in video_list[:50]: # Iterate on video files\n",
    "\n",
    "    print(f\"Processing video: {vid_name}\")\n",
    "\n",
    "    if vid_name.endswith('.mpg'):\n",
    "        vid_path = VIDEO_PATH + vid_name\n",
    "        vid = cv2.VideoCapture(vid_path)\n",
    "\n",
    "        frames = []               # A list to hold frame images\n",
    "        frames_colour = []         # A list to hold original frame images\n",
    "        while(True):\n",
    "            success, frame = vid.read()\n",
    "                # Read frame\n",
    "            if not success:\n",
    "                break                           # Break if no frame to read left\n",
    "            gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)   # Convert image into grayscale\n",
    "            frames.append(gray)                  # Add image to the frame buffer\n",
    "            frames_colour.append(frame)\n",
    "\n",
    "        vid.release()\n",
    "\n",
    "        landmarks = []\n",
    "        for (i, image) in enumerate(frames):          #iterate on frame lis\n",
    "            face_rects = detector(image,1)             #detects face\n",
    "            if len(face_rects) < 1:                 #no faces\n",
    "                print(f\"No face detected: {vid_path}\")\n",
    "                continue\n",
    "            if len(face_rects) > 1:                  #too many faces\n",
    "                print(f\"Too many faces: {vid_path}\")\n",
    "                continue\n",
    "            rect = face_rects[0]                    #proper number of faces\n",
    "            landmark = predictor(image, rect)   #detect face landmarks\n",
    "            landmark = shape_to_list(landmark)\n",
    "            landmarks.append(landmark)\n",
    "\n",
    "        cropped_img = []\n",
    "        for (i,landmark) in enumerate(landmarks):\n",
    "            lip_landmark = landmark[48:68]                                          # Landmark corresponding to lip\n",
    "            lip_x = sorted(lip_landmark,key = lambda pointx: pointx[0])             # Lip landmark sorted for determining lip region\n",
    "            lip_y = sorted(lip_landmark, key = lambda pointy: pointy[1])\n",
    "            x_add = int((-lip_x[0][0]+lip_x[-1][0])*LIP_MARGIN*1)                     # Determine Margins for lip-only image\n",
    "            y_add = int((-lip_y[0][1]+lip_y[-1][1])*LIP_MARGIN*2)\n",
    "            crop_pos = (lip_x[0][0]-x_add, lip_x[-1][0]+x_add, lip_y[0][1]-y_add, lip_y[-1][1]+y_add)\n",
    "            cropped = frames_colour[i][crop_pos[2]:crop_pos[3],crop_pos[0]:crop_pos[1]]        # Crop image\n",
    "            cropped = cv2.resize(cropped,(RESIZE[0],RESIZE[1]),interpolation=cv2.INTER_CUBIC)       # Resize\n",
    "            cropped_img.append(cropped)\n",
    "\n",
    "        print('------------ images cropped ----------')\n",
    "\n",
    "        cropped_img_list.append(cropped_img)\n",
    "\n",
    "        print(f\"VIDEO COMPLETED: {vid_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeitgray(image_pls, i, j):\n",
    "    return np.dot(image_pls[i][j][...,:3], [0.2989, 0.5780, 0.1440])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_image_list = []\n",
    "for i, image in enumerate(cropped_img_list):\n",
    "    gray_frame_list = []\n",
    "    for j, frame in enumerate(image):\n",
    "        gray_image = makeitgray(cropped_img_list,i,j)\n",
    "        # comment this out if you don't need the shape (X, X, 1)\n",
    "        gray_image = np.expand_dims(gray_image, axis=2)\n",
    "        gray_frame_list.append(gray_image)\n",
    "    gray_image_list.append(gray_frame_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(vid):\n",
    "    mean_vid = vid.mean(axis=0)\n",
    "    std_vid = vid.std(axis=0)\n",
    "    return (vid-mean_vid)/std_vid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized_list=[]\n",
    "for vid in gray_image_list:\n",
    "    #print(type(vid))\n",
    "    vid= np.array(vid)\n",
    "    standard_vid = standardize(vid)\n",
    "    standardized_list.append(standard_vid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_keys=[]\n",
    "for vid_name in video_list:\n",
    "    dict_keys.append(vid_name.replace('.mpg', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_vids= dict(zip(dict_keys, standardized_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('zipped_vids.npz', **final_vids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_data = np.load('zipped_vids.npz', allow_pickle=True).items()\n",
    "# loaded_dict = {key: val for key, val in loaded_data}\n",
    "\n",
    "# print(loaded_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# for key, value in final_vids.items():\n",
    "#     if isinstance(value, np.ndarray):\n",
    "#         final_vids[key] = value.tolist()\n",
    "\n",
    "# with open ('preprocessed_data.json', 'w') as f:\n",
    "#     json.dump(final_vids, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lip_translate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

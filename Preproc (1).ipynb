{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16d149ec-3390-4f92-a93d-1d68d2b96c42",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.10/site-packages (4.9.0.80)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (3.8.3)\n",
      "Requirement already satisfied: imageio in /opt/conda/lib/python3.10/site-packages (2.34.0)\n",
      "Requirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.11.0)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /opt/conda/lib/python3.10/site-packages (from opencv-python) (1.24.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (4.48.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.48.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (16.0.6)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.19.6)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (69.0.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.11.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.29.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.27.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (3.5.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.1.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python matplotlib imageio tensorflow\n",
    "#gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "593dddc4-8ced-43bb-90a6-651f72546ec6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-06 14:13:16.835390: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-06 14:13:16.949296: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-06 14:13:17.670479: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib/python3.10/site-packages/cv2/../../lib64:/usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2024-03-06 14:13:17.670571: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib/python3.10/site-packages/cv2/../../lib64:/usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2024-03-06 14:13:17.670579: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from matplotlib import pyplot as plt\n",
    "import imageio\n",
    "# import gdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff15671-825e-4d08-84e7-5ac3b437207b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Get file names for speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c4a5b85-461a-48e9-876a-3b6c745593e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "speaker = 's1'\n",
    "\n",
    "folders_to_clean = [speaker]\n",
    "paths_to_clean = ['/'.join([os.getcwd(),'data/raw_videos', folder]) for folder in folders_to_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b32038a-87ac-44b1-a708-694c40330619",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/jupyter/lip_translate/data/raw_videos/s1']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths_to_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a999091d-c195-405b-80a6-bc9ef829bf10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# file_names = []\n",
    "# for folder_path in paths_to_clean:\n",
    "#     for root, dirs, files in os.walk(folder_path):\n",
    "#         for file in files:\n",
    "#             if file.endswith('mpg'):\n",
    "#                 file_name = file.replace(\".mpg\", \"\")\n",
    "#                 if len(file_names) < 6: #Temporary -- comment out cell below when this is working\n",
    "#                     file_names.append(file_name)\n",
    "# file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1cbb7e9-a4df-44ca-b8e9-20cf1c52693f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_names = []\n",
    "for folder_path in paths_to_clean:\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.endswith('mpg'):\n",
    "                file_name = file.replace(\".mpg\", \"\")\n",
    "                file_names.append(file_name)\n",
    "# file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb273545-063f-473d-9bac-23e3fa9869f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# align_names = [file.replace('.align', '') for file in os.listdir('/home/jupyter/data/raw_alignments/s11')]\n",
    "# video_names = [file.replace('.mpg', '') for file in os.listdir('/home/jupyter/data/raw_videos/s11')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299564c4-19bd-429b-b11a-e4d61dbad4e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# align_in_vid = []\n",
    "\n",
    "# for alignment in align_names:\n",
    "#     if alignment in video_names:\n",
    "#         align_in_vid.append(alignment)\n",
    "#         # print(alignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dc1144-b6fc-461f-a79b-9e4bc6cfabf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# vid_in_align = []\n",
    "\n",
    "# for vid in video_names:\n",
    "#     if vid in align_names:\n",
    "#         vid_in_align.append(vid)\n",
    "#         # print(vid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7d4354-83f6-4ba8-b3f9-502f14404668",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# len(vid_in_align), len(video_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c61ce58-1e75-411b-b3fe-af474521d68f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# len(align_in_vid), len(align_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f139b5ea-2045-43f8-8a6b-c6130ae0d593",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# vid_in_align"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b016c2-1ffa-4b35-ad23-d26ee58f6cb7",
   "metadata": {},
   "source": [
    "### Create function to load video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f130b7c-fd67-4b29-a401-a288e1cbddf3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_video(path:str) -> List[float]: #Returns a list of the normalized, greyscaled frames of the video of shape=(75, 46, 140, 1)\n",
    "\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames = []\n",
    "    for _ in range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))): \n",
    "        ret, frame = cap.read()\n",
    "        frame = tf.image.rgb_to_grayscale(frame)\n",
    "        frames.append(frame[190:236,80:220,:]) #There is a better way of doing this\n",
    "    cap.release()\n",
    "    \n",
    "    mean = tf.math.reduce_mean(frames)\n",
    "    std = tf.math.reduce_std(tf.cast(frames, tf.float32))\n",
    "    return tf.cast((frames - mean), tf.float32) / std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d968e9aa-3474-4d2c-a3b1-17fca6583ee5",
   "metadata": {},
   "source": [
    "### Define vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e4388ab-3fc4-4573-8ec0-d003447ee568",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-06 14:15:41.489008: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib/python3.10/site-packages/cv2/../../lib64:/usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2024-03-06 14:15:41.489036: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-03-06 14:15:41.489059: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-20240305-111814): /proc/driver/nvidia/version does not exist\n",
      "2024-03-06 14:15:41.489324: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "vocab = [x for x in \"abcdefghijklmnopqrstuvwxyz'?!123456789 \"]\n",
    "\n",
    "char_to_num = tf.keras.layers.StringLookup(vocabulary=vocab, oov_token=\"\")\n",
    "num_to_char = tf.keras.layers.StringLookup(\n",
    "    vocabulary=char_to_num.get_vocabulary(), oov_token=\"\", invert=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e917c4-9d0c-4cdf-b034-b8ea7f2ddc4d",
   "metadata": {},
   "source": [
    "### Define function to get alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2d119da-177d-40a2-a9f0-f829ed6d9418",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_alignments(path:str) -> List[str]: \n",
    "    with open(path, 'r') as f: \n",
    "        lines = f.readlines() \n",
    "    tokens = []\n",
    "    for line in lines:\n",
    "        line = line.split()\n",
    "        if line[2] != 'sil': #Removing the silences\n",
    "            tokens = [*tokens,' ',line[2]]\n",
    "    return char_to_num(tf.reshape(tf.strings.unicode_split(tokens, input_encoding='UTF-8'), (-1)))[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e25527-eb18-435e-8e77-8c5e2ef9ba57",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Define function to load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4aca4b00-0ffa-4744-bdf6-803153fb5269",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data(file_name: str): \n",
    "    video_path = os.path.join(os.getcwd(),'data/raw_videos', speaker, f'{file_name}.mpg')\n",
    "    alignment_path = os.path.join(os.getcwd(),'data/raw_alignments', speaker, f'{file_name}.align')\n",
    "    frames = load_video(video_path).numpy().tolist()\n",
    "    alignments = load_alignments(alignment_path).numpy().tolist()\n",
    "\n",
    "    return frames, alignments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbab76d-78e0-4beb-a8ac-32d0e0eaaf08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# file_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede9cbf3-5e11-49a0-8b84-5ee4f81e2167",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load_data(file_names[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af60f8e2-d4aa-4918-a8da-54b8e1e31f41",
   "metadata": {},
   "source": [
    "### Build dictionary to store outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95eb1223-e282-446f-a05f-8d0ab2a63f01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d73e10e-c580-4398-988b-c4a23697aff5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clean_data = dict.fromkeys(file_names, {'clean_frames':None,\n",
    "                                        'clean_alignments':None})\n",
    "\n",
    "# clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154fde22-64fc-4977-bf81-55782af66792",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# clean_data['lgis1a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "abda23cf-111b-4c07-850e-d0043cc8f3f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_data('lgis1a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbd50d4a-021a-4c99-bbb2-6a84bc94d34c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_dict(file_names):\n",
    "    for file_name in file_names:\n",
    "        output_dict = clean_data[file_name]\n",
    "        output_dict['clean_frames'], output_dict['clean_alignments'] = load_data(file_name)\n",
    "        clean_data[file_name] = output_dict\n",
    "    return clean_data\n",
    "    \n",
    "        \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7cce65fd-9efe-451c-833b-1558c154b090",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7fe7b64dba60>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 770, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n",
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7fe7b64dba60>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 770, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m clean_dict \u001b[38;5;241m=\u001b[39m \u001b[43mmake_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# clean_dict\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[13], line 4\u001b[0m, in \u001b[0;36mmake_dict\u001b[0;34m(file_names)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_name \u001b[38;5;129;01min\u001b[39;00m file_names:\n\u001b[1;32m      3\u001b[0m     output_dict \u001b[38;5;241m=\u001b[39m clean_data[file_name]\n\u001b[0;32m----> 4\u001b[0m     output_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclean_frames\u001b[39m\u001b[38;5;124m'\u001b[39m], output_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclean_alignments\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     clean_data[file_name] \u001b[38;5;241m=\u001b[39m output_dict\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m clean_data\n",
      "Cell \u001b[0;32mIn[10], line 4\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m(file_name)\u001b[0m\n\u001b[1;32m      2\u001b[0m video_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mgetcwd(),\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/raw_videos\u001b[39m\u001b[38;5;124m'\u001b[39m, speaker, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.mpg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m alignment_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mgetcwd(),\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/raw_alignments\u001b[39m\u001b[38;5;124m'\u001b[39m, speaker, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.align\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m frames \u001b[38;5;241m=\u001b[39m \u001b[43mload_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_path\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m      5\u001b[0m alignments \u001b[38;5;241m=\u001b[39m load_alignments(alignment_path)\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frames, alignments\n",
      "Cell \u001b[0;32mIn[7], line 8\u001b[0m, in \u001b[0;36mload_video\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      6\u001b[0m     ret, frame \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m      7\u001b[0m     frame \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mrgb_to_grayscale(frame)\n\u001b[0;32m----> 8\u001b[0m     frames\u001b[38;5;241m.\u001b[39mappend(\u001b[43mframe\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m190\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m236\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m80\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m220\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m) \u001b[38;5;66;03m#There is a better way of doing this\u001b[39;00m\n\u001b[1;32m      9\u001b[0m cap\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m     11\u001b[0m mean \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mreduce_mean(frames)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1175\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1176\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1178\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1179\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1180\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/array_ops.py:1071\u001b[0m, in \u001b[0;36m_slice_helper\u001b[0;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[1;32m   1066\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(\n\u001b[1;32m   1067\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1068\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrided_slice\u001b[39m\u001b[38;5;124m\"\u001b[39m, [tensor] \u001b[38;5;241m+\u001b[39m begin \u001b[38;5;241m+\u001b[39m end \u001b[38;5;241m+\u001b[39m strides,\n\u001b[1;32m   1069\u001b[0m     skip_on_eager\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m name:\n\u001b[1;32m   1070\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m begin:\n\u001b[0;32m-> 1071\u001b[0m     packed_begin, packed_end, packed_strides \u001b[38;5;241m=\u001b[39m (stack(begin), \u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1072\u001b[0m                                                 stack(strides))\n\u001b[1;32m   1073\u001b[0m     \u001b[38;5;66;03m# TODO(mdan): Instead of implicitly casting, it's better to enforce the\u001b[39;00m\n\u001b[1;32m   1074\u001b[0m     \u001b[38;5;66;03m# same dtypes.\u001b[39;00m\n\u001b[1;32m   1075\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (packed_begin\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mint64 \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1076\u001b[0m         packed_end\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mint64 \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1077\u001b[0m         packed_strides\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mint64):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:140\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21merror_handler\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    139\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 140\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mis_traceback_filtering_enabled\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    141\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    142\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNameError\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;66;03m# In some very rare cases,\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;66;03m# `is_traceback_filtering_enabled` (from the outer scope) may not be\u001b[39;00m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;66;03m# accessible from inside this function\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:32\u001b[0m, in \u001b[0;36mis_traceback_filtering_enabled\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m _ENABLE_TRACEBACK_FILTERING \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mlocal()\n\u001b[1;32m     27\u001b[0m _EXCLUDED_PATHS \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     28\u001b[0m     os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;18m__file__\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m'\u001b[39m)),\n\u001b[1;32m     29\u001b[0m )\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdebugging.is_traceback_filtering_enabled\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_traceback_filtering_enabled\u001b[39m():\n\u001b[1;32m     34\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Check whether traceback filtering is currently enabled.\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \n\u001b[1;32m     36\u001b[0m \u001b[38;5;124;03m  See also `tf.debugging.enable_traceback_filtering()` and\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;124;03m    was called).\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m     47\u001b[0m   value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_ENABLE_TRACEBACK_FILTERING, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clean_dict = make_dict(file_names)\n",
    "# clean_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7535eef3-dfa9-443b-bdcf-04dd5859982c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(clean_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28518da9-1589-4685-aea8-44f8e350d26a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb46fef-9cfe-4e12-9ea2-ea220806e3b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Testing converting eager tensor type to list in order to save to json\n",
    "\n",
    "# clean_vid = clean_dict['lgis1a'].copy()\n",
    "# clean_vid['clean_frames'] = clean_vid['clean_frames']\n",
    "# clean_vid['clean_alignments'] = clean_vid['clean_alignments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c3e1c3-7180-4480-bd9b-8af1b327b97c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clean_vid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47ff1a7-aca4-4a07-9290-6acef432c0e5",
   "metadata": {},
   "source": [
    "### Save to a JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a811dcea-5b89-4fd3-8ebf-4ee347c590e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# with open('data/processed_data/test_vid.json', 'w') as fp:\n",
    "#     json.dump(clean_vid, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4324da5-ecc4-4a50-a1ca-9a1852e8f8ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# f = open('data/processed_data/test_vid.json')\n",
    "\n",
    "# test_vid = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c6eea2-2196-4c79-bf3e-40b465f4879f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# len(test_vid['clean_frames'][0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9dc51d-61ad-4dc9-a6a5-9ceb000738e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plt.imshow(test_vid['clean_frames'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb19ea3c-f5c9-446f-b1f4-154432fce525",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m117",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m117"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
